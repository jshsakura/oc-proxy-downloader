"""
í•µì‹¬ ë‹¤ìš´ë¡œë“œ ë¡œì§ ëª¨ë“ˆ
- 1fichier íŒŒì¼ ë‹¤ìš´ë¡œë“œ
- í”„ë¡ì‹œ ìˆœí™˜ ë‹¤ìš´ë¡œë“œ
- íŒŒì¼ ê´€ë¦¬
"""

import os
import re
import time
import threading
import requests
import json
from pathlib import Path
from sqlalchemy.orm import Session

from .db import get_db
from .models import DownloadRequest, StatusEnum
from .config import get_download_path, get_config
from .proxy_manager import get_unused_proxies, mark_proxy_used
from .parser_service import get_or_parse_direct_link


def format_file_size(bytes_size):
    """íŒŒì¼ í¬ê¸°ë¥¼ ì ì ˆí•œ ë‹¨ìœ„ë¡œ í¬ë§·íŒ…"""
    if bytes_size == 0:
        return "0 B"
    
    units = ["B", "KB", "MB", "GB", "TB", "PB"]
    unit_index = 0
    size = float(bytes_size)
    
    while size >= 1024 and unit_index < len(units) - 1:
        size /= 1024
        unit_index += 1
    
    # ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€ í‘œì‹œ, ë¶ˆí•„ìš”í•œ 0 ì œê±°
    if unit_index == 0:  # Bytes
        return f"{int(size)} {units[unit_index]}"
    else:
        return f"{size:.2f} {units[unit_index]}".rstrip('0').rstrip('.')


def send_websocket_message(message_type: str, data: dict):
    """WebSocket ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # main.pyì˜ status_queueì— ë©”ì‹œì§€ ì „ì†¡
        from core.shared import status_queue
        message = json.dumps({
            "type": message_type,
            "data": data
        }, ensure_ascii=False)
        status_queue.put(message)
        # print(f"[LOG] WebSocket ë©”ì‹œì§€ ì „ì†¡: {message_type}")
    except Exception as e:
        print(f"[LOG] WebSocket ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {e}")

def get_unique_filepath(path: Path) -> Path:
    """
    íŒŒì¼ ê²½ë¡œê°€ ì¡´ì¬í•  ê²½ìš°, ê´„í˜¸ ì•ˆì— ìˆ«ìë¥¼ ë¶™ì—¬ ê³ ìœ í•œ ê²½ë¡œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    (ì˜ˆ: 'file.txt' -> 'file (1).txt')
    """
    if not path.exists():
        return path

    counter = 1
    original_stem = path.stem
    original_suffix = path.suffix
    directory = path.parent

    while True:
        new_stem = f"{original_stem} ({counter})"
        new_path = directory / (new_stem + original_suffix)
        if not new_path.exists():
            return new_path
        counter += 1






def get_translations(lang: str = "ko") -> dict:
    """ë²ˆì—­ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        import os
        locale_file = os.path.join(os.path.dirname(__file__), "..", "locales", f"{lang}.json")
        if os.path.exists(locale_file):
            with open(locale_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    except Exception:
        return {}


def send_telegram_wait_notification(file_name: str, wait_minutes: int, lang: str = "ko"):
    """ëŒ€ê¸°ì‹œê°„ í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ (5ë¶„ ì´ìƒ ëŒ€ê¸°ì‹œê°„)"""
    try:
        config = get_config()
        
        bot_token = config.get("telegram_bot_token", "").strip()
        chat_id = config.get("telegram_chat_id", "").strip()
        notify_wait = config.get("telegram_notify_wait", True)  # ëŒ€ê¸°ì‹œê°„ ì•Œë¦¼ ì„¤ì •
        
        # ì„¤ì •ì´ ì—†ê±°ë‚˜ ëŒ€ê¸°ì‹œê°„ ì•Œë¦¼ì´ ë¹„í™œì„±í™”ëœ ê²½ìš°
        if not bot_token or not chat_id or not notify_wait:
            return
        
        # ë²ˆì—­ ê°€ì ¸ì˜¤ê¸°
        translations = get_translations(lang)
        
        # HTML í˜•ì‹ìœ¼ë¡œ ì˜ˆìœ ë©”ì‹œì§€ ì‘ì„±
        import datetime
        if lang == "ko":
            # í•œêµ­ì–´ì¼ ë•Œë§Œ KSTë¡œ í‘œì‹œ
            current_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=9)).strftime("%Y-%m-%d %H:%M:%S")
        else:
            # ì˜ì–´ ë“± ë‹¤ë¥¸ ì–¸ì–´ëŠ” UTCë¡œ í‘œì‹œ
            current_time = datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
        
        wait_text = translations.get("telegram_wait_detected", "Wait Time Detected")
        filename_text = translations.get("telegram_filename", "Filename")
        wait_time_text = translations.get("telegram_wait_time", "Wait Time")
        filesize_text = translations.get("telegram_filesize", "File Size")
        
        message = f"""ğŸ”” <b>OC-Proxy: {wait_text}</b> â³

ğŸ“ <b>{filename_text}</b>
<code>{file_name}</code>

ğŸ“Š <b>{filesize_text}</b>
<code>{filesize_text or 'ì•Œ ìˆ˜ ì—†ìŒ'}</code>

â° <b>{wait_time_text}</b>
<code>{wait_minutes}ë¶„</code>"""
        
        # í…”ë ˆê·¸ë¨ API í˜¸ì¶œ (ë¹„ë™ê¸°)
        import requests
        import threading
        
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        payload = {
            "chat_id": chat_id,
            "text": message,
            "parse_mode": "HTML"
        }
        
        def send_async():
            try:
                response = requests.post(url, json=payload, timeout=10)
                if response.status_code == 200:
                    print(f"[LOG] í…”ë ˆê·¸ë¨ ëŒ€ê¸°ì‹œê°„ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ: {file_name} ({wait_minutes}ë¶„)")
                else:
                    print(f"[WARN] í…”ë ˆê·¸ë¨ ëŒ€ê¸°ì‹œê°„ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
            except Exception as e:
                print(f"[WARN] í…”ë ˆê·¸ë¨ ëŒ€ê¸°ì‹œê°„ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
        
        threading.Thread(target=send_async, daemon=True).start()
        
    except Exception as e:
        print(f"[WARN] í…”ë ˆê·¸ë¨ ëŒ€ê¸°ì‹œê°„ ì•Œë¦¼ ì„¤ì • ì˜¤ë¥˜: {e}")


def utc_to_kst(utc_time_str: str) -> str:
    """UTC ì‹œê°„ ë¬¸ìì—´ì„ KSTë¡œ ë³€í™˜"""
    try:
        import datetime
        # ISO í˜•ì‹ì˜ UTC ì‹œê°„ì„ íŒŒì‹±
        if utc_time_str.endswith('Z'):
            utc_time_str = utc_time_str[:-1]
        
        utc_dt = datetime.datetime.fromisoformat(utc_time_str)
        # UTC+9 (í•œêµ­ ì‹œê°„) ì ìš©
        kst_dt = utc_dt + datetime.timedelta(hours=9)
        return kst_dt.strftime("%Y-%m-%d %H:%M:%S")
    except:
        return utc_time_str or "ì•Œ ìˆ˜ ì—†ìŒ"

def send_telegram_notification(file_name: str, status: str, error: str = None, lang: str = "ko", file_size: str = None, download_time: str = None, save_path: str = None, requested_time: str = None):
    """í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡"""
    try:
        config = get_config()
        
        bot_token = config.get("telegram_bot_token", "").strip()
        chat_id = config.get("telegram_chat_id", "").strip()
        notify_success = config.get("telegram_notify_success", False)
        notify_failure = config.get("telegram_notify_failure", True)
        
        # ì„¤ì •ì´ ì—†ìœ¼ë©´ ì•Œë¦¼ ì „ì†¡í•˜ì§€ ì•ŠìŒ
        if not bot_token or not chat_id:
            return
            
        # ì•Œë¦¼ ì„¤ì •ì— ë”°ë¼ ì „ì†¡ ì—¬ë¶€ ê²°ì •
        if status == "done" and not notify_success:
            return
        if status == "failed" and not notify_failure:
            return
        
        # ë²ˆì—­ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        translations = get_translations(lang)
        
        # HTML í˜•ì‹ìœ¼ë¡œ ì˜ˆìœ ë©”ì‹œì§€ ì‘ì„±
        import datetime
        if lang == "ko":
            # í•œêµ­ì–´ì¼ ë•Œë§Œ KSTë¡œ í‘œì‹œ
            current_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=9)).strftime("%Y-%m-%d %H:%M:%S")
        else:
            # ì˜ì–´ ë“± ë‹¤ë¥¸ ì–¸ì–´ëŠ” UTCë¡œ í‘œì‹œ
            current_time = datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
        
        if status == "done":
            success_text = translations.get("telegram_download_success", "Download Complete")
            filename_text = translations.get("telegram_filename", "Filename")
            filesize_text = translations.get("telegram_filesize", "íŒŒì¼í¬ê¸°")
            requested_time_text = translations.get("telegram_requested_time", "ìš”ì²­ì‹œê°„")
            completed_time_text = translations.get("telegram_completed_time", "ì™„ë£Œì‹œê°„")
            save_path_text = translations.get("telegram_save_path", "ì €ì¥ê²½ë¡œ")

            message = f"""ğŸ”” <b>OC-Proxy: {success_text}</b> ğŸ‰

ğŸ“ <b>{filename_text}</b>
<code>{file_name}</code>

ğŸ“Š <b>{filesize_text}</b>
<code>{file_size or 'ì•Œ ìˆ˜ ì—†ìŒ'}</code>

ğŸ“¥ <b>{requested_time_text}</b>
<code>{requested_time or 'ì•Œ ìˆ˜ ì—†ìŒ'}</code>

âœ… <b>{completed_time_text}</b>
<code>{download_time or current_time}</code>

ğŸ’¾ <b>{save_path_text}</b>
<code>{save_path or 'ê¸°ë³¸ê²½ë¡œ'}</code>"""

        elif status == "failed":
            failed_text = translations.get("telegram_download_failed", "Download Failed")
            filename_text = translations.get("telegram_filename", "Filename")
            error_text = translations.get("telegram_error", "Error")
            failed_time_text = translations.get("telegram_failed_time", "ì‹¤íŒ¨ì‹œê°„")

            error_msg = error[:200] + '...' if error and len(error) > 200 else error or 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'

            message = f"""ğŸ”” <b>OC-Proxy: {failed_text}</b> âŒ

ğŸ“ <b>{filename_text}</b>
<code>{file_name}</code>

âš ï¸ <b>{error_text}</b>
<code>{error_msg}</code>

ğŸ• <b>{failed_time_text}</b>
<code>{current_time}</code>"""
        else:
            return
            
        # í…”ë ˆê·¸ë¨ API í˜¸ì¶œ
        import requests
        
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        payload = {
            "chat_id": chat_id,
            "text": message,
            "parse_mode": "HTML"
        }
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì „ì†¡ (ë¸”ë¡œí‚¹ ë°©ì§€)
        def send_async():
            try:
                response = requests.post(url, json=payload, timeout=10)
                if response.status_code == 200:
                    print(f"[LOG] í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ: {file_name}")
                else:
                    print(f"[WARN] í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
            except Exception as e:
                print(f"[WARN] í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
        
        threading.Thread(target=send_async, daemon=True).start()
        
    except Exception as e:
        print(f"[WARN] í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì„¤ì • ì˜¤ë¥˜: {e}")


def should_retry_download(retry_count: int, error_message: str) -> bool:
    """ë‹¤ìš´ë¡œë“œ ì¬ì‹œë„ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜"""
    
    # ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ê²€ì‚¬ ë¨¼ì € ìˆ˜í–‰
    retry_network_errors = [
        "nameresolutionerror",
        "getaddrinfo failed",
        "failed to resolve",
        "connection timeout",
        "connection refused",
        "network is unreachable",
        "temporary failure in name resolution",
        "max retries exceeded",
        "connection aborted",
        "connection reset",
        "httpsconnectionpool",
        "errno 11001",
        "name or service not known",
        "nodename nor servname provided",
        "dns resolution failed"
    ]
    
    error_lower = error_message.lower()
    is_network_error = any(retry_error in error_lower for retry_error in retry_network_errors)
    
    # ìµœëŒ€ 10ë²ˆê¹Œì§€ ì¬ì‹œë„ í—ˆìš©
    max_retries_for_error = 10
    
    # ì¬ì‹œë„ í•œë„ í™•ì¸
    if retry_count >= max_retries_for_error:
        print(f"[LOG] ì¬ì‹œë„ í•œë„ ì´ˆê³¼: {retry_count}/{max_retries_for_error}")
        return False
    
    # dstorage.fr DNS ì˜¤ë¥˜ëŠ” 1fichier ë§í¬ ë§Œë£Œë¥¼ ì˜ë¯¸í•˜ë¯€ë¡œ ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
    if "dstorage.fr" in error_lower:
        print(f"[LOG] dstorage.fr DNS ì˜¤ë¥˜ - 1fichier ë§í¬ ë§Œë£Œë¡œ íŒë‹¨, ì¬ì‹œë„ ì¤‘ë‹¨")
        return False
    
    # ì¼ë°˜ì ì¸ DNS í•´ê²° ì‹¤íŒ¨ë„ ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ (ë§í¬ ë§Œë£Œ ê°€ëŠ¥ì„± ë†’ìŒ)
    if any(dns_error in error_lower for dns_error in [
        "failed to resolve", "name or service not known", 
        "no address associated with hostname", "nameresolutionerror"
    ]):
        print(f"[LOG] DNS í•´ê²° ì‹¤íŒ¨ - ë§í¬ ë§Œë£Œë¡œ íŒë‹¨, ì¬ì‹œë„ ì¤‘ë‹¨")
        return False
    
    # ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜ë“¤
    no_retry_errors = [
        "404",  # íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ
        "not found",
        "file not found",
        "invalid url",
        "íŒŒì‹± ì‹¤íŒ¨",  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
        "direct linkë¥¼ ì°¾ì„ ìˆ˜ ì—†",  # ë‹¤ìš´ë¡œë“œ ë§í¬ íŒŒì‹± ì‹¤íŒ¨
        "ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†",  # ë‹¤ìš´ë¡œë“œ ë§í¬ íŒŒì‹± ì‹¤íŒ¨
        "parsing failed",  # ì˜ë¬¸ íŒŒì‹± ì‹¤íŒ¨
        "link expired",  # ë§í¬ ë§Œë£Œ
        "invalid link",
        "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "ì˜ëª»ëœ ë§í¬",
        "permission denied",
        "access denied",
        "unauthorized",
        "forbidden"
    ]
    
    # ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ì¸ì§€ ì´ë¯¸ ìœ„ì—ì„œ í™•ì¸í–ˆìœ¼ë¯€ë¡œ, ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜ë§Œ ì²´í¬
    for no_retry_error in no_retry_errors:
        if no_retry_error in error_lower:
            print(f"[LOG] ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜: {error_message}")
            return False
    
    if is_network_error:
        print(f"[LOG] ì¬ì‹œë„ ê°€ëŠ¥í•œ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {error_message}")
    else:
        print(f"[LOG] ì¬ì‹œë„ ê°€ëŠ¥í•œ ì¼ë°˜ ì˜¤ë¥˜: {error_message}")
    
    return True


def should_1fichier_auto_retry(url: str, file_name: str, file_size: str, fichier_retry_count: int, error_message: str) -> bool:
    """1fichier ë¬´ë£Œ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜"""
    
    # 1fichier URLì´ ì•„ë‹ˆë©´ ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
    if "1fichier.com" not in url.lower():
        return False
    
    # íŒŒì¼ëª…ê³¼ ìš©ëŸ‰ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ì´ë¯€ë¡œ ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
    if not file_name or not file_size:
        print(f"[LOG] 1fichier ìë™ ì¬ì‹œë„ ë¶ˆê°€: íŒŒì¼ëª…({file_name}) ë˜ëŠ” ìš©ëŸ‰({file_size}) ì—†ìŒ")
        return False
    
    # íŒŒì¼ëª…ì´ ê¸°ë³¸ê°’ì´ë©´ ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
    if file_name in ['1fichier.com: Cloud Storage', 'ì•Œ ìˆ˜ ì—†ìŒ']:
        print(f"[LOG] 1fichier ìë™ ì¬ì‹œë„ ë¶ˆê°€: íŒŒì¼ëª…ì´ ê¸°ë³¸ê°’({file_name})")
        return False
    
    # ìµœëŒ€ 10íšŒê¹Œì§€ ì¬ì‹œë„ í—ˆìš©
    if fichier_retry_count >= 10:
        print(f"[LOG] 1fichier ìë™ ì¬ì‹œë„ í•œë„ ì´ˆê³¼: {fichier_retry_count}/10")
        return False
    
    # ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜ë“¤ (ë§í¬ ë§Œë£Œ, ê¶Œí•œ ë¬¸ì œ ë“±)
    no_retry_errors = [
        "404",
        "not found", 
        "file not found",
        "invalid url",
        "link expired",
        "invalid link",
        "permission denied",
        "access denied", 
        "unauthorized",
        "forbidden",
        "dstorage.fr",
        "íŒŒì‹± ì‹¤íŒ¨",
        "direct linkë¥¼ ì°¾ì„ ìˆ˜ ì—†",
        "ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†"
    ]
    
    error_lower = error_message.lower()
    for no_retry_error in no_retry_errors:
        if no_retry_error in error_lower:
            print(f"[LOG] 1fichier ìë™ ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜: {error_message}")
            return False
    
    print(f"[LOG] 1fichier ìë™ ì¬ì‹œë„ ê°€ëŠ¥: {fichier_retry_count + 1}/10")
    return True


def download_1fichier_file_new(request_id: int, lang: str = "ko", use_proxy: bool = True, retry_count: int = 0, fichier_retry_count: int = 0):
    """
    ìƒˆë¡œìš´ í”„ë¡ì‹œ ìˆœí™˜ ë¡œì§ì„ ì‚¬ìš©í•œ 1fichier ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
    """
    print("=" * 80)
    print(f"[LOG] *** ìƒˆë¡œìš´ ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ ì‹œì‘ ***")
    print(f"[LOG] Request ID: {request_id}")
    print(f"[LOG] Use Proxy: {use_proxy}")
    print(f"[LOG] ì‹œì‘ ì‹œê°„: {time.strftime('%H:%M:%S')}")
    print(f"[LOG] ì¬ì‹œë„ ì¹´ìš´í„°: {retry_count}, 1fichier ì¬ì‹œë„ ì¹´ìš´í„°: {fichier_retry_count}")
    print("=" * 80)
    
    # ë¡œì»¬ ë‹¤ìš´ë¡œë“œ ë“±ë¡ (1fichierë§Œ)
    from .shared import download_manager
    
    # ìƒˆë¡œìš´ DB ì„¸ì…˜ ìƒì„±
    from .db import SessionLocal
    db = SessionLocal()
    req = None
    
    try:
        # ìš”ì²­ ì •ë³´ ì¡°íšŒ
        req = db.query(DownloadRequest).filter(DownloadRequest.id == request_id).first()
        if req is None:
            print(f"[LOG] ë‹¤ìš´ë¡œë“œ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: ID {request_id}")
            return
            
        # ì§€ì—° ì‹œê°„ ì²´í¬ (5ë²ˆ ì´í›„ ì¬ì‹œë„ì—ì„œ 3ë¶„ ì§€ì—°)
        if req.error and "delay_until:" in req.error:
            try:
                import datetime
                delay_part = req.error.split("delay_until:")[1].strip()
                delay_until = datetime.datetime.fromisoformat(delay_part)
                current_time = datetime.datetime.utcnow()
                
                if current_time < delay_until:
                    remaining_seconds = int((delay_until - current_time).total_seconds())
                    print(f"[LOG] ì¬ì‹œë„ ì§€ì—° ì‹œê°„ ëŒ€ê¸° ì¤‘: {remaining_seconds}ì´ˆ ë‚¨ìŒ - ID {request_id}")
                    # ì§€ì—° ì‹œê°„ì´ ë‚¨ì•„ìˆìœ¼ë©´ ë‹¤ì‹œ ëŒ€ê¸° ìƒíƒœë¡œ ìœ ì§€
                    req.status = StatusEnum.pending
                    req.error = req.error.replace("delay_until:", f"ì§€ì—°ëŒ€ê¸° ì¤‘ ({remaining_seconds}ì´ˆ ë‚¨ìŒ) delay_until:")
                    db.commit()
                    return
                else:
                    # ì§€ì—° ì‹œê°„ì´ ì§€ë‚¬ìœ¼ë©´ delay_until ë¶€ë¶„ ì œê±°
                    req.error = req.error.split(" | delay_until:")[0] if " | delay_until:" in req.error else req.error
                    db.commit()
                    print(f"[LOG] ì§€ì—° ì‹œê°„ ì™„ë£Œ, ë‹¤ìš´ë¡œë“œ ì§„í–‰ - ID {request_id}")
            except Exception as delay_error:
                print(f"[LOG] ì§€ì—° ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜: {delay_error}")
                # íŒŒì‹± ì˜¤ë¥˜ ì‹œ ê·¸ëƒ¥ ì§„í–‰
        
        # ì •ì§€ ìƒíƒœ ì²´í¬
        if req.status == StatusEnum.stopped:
            print(f"[LOG] ë‹¤ìš´ë¡œë“œê°€ ì´ë¯¸ ì •ì§€ëœ ìƒíƒœ: ID {request_id}")
            return
        
        print(f"[LOG] URL: {req.url}")
        print(f"[LOG] íŒŒì¼ëª…: {req.file_name}")
        print(f"[DEBUG] â˜… DBì—ì„œ ì¡°íšŒí•œ req.file_name íƒ€ì…: {type(req.file_name)}")
        print(f"[DEBUG] â˜… DBì—ì„œ ì¡°íšŒí•œ req.file_name ê°’: '{req.file_name}'")
        
        # í”„ë¡ì‹œê°€ ì•„ë‹Œ ê²½ìš° ë‹¤ìš´ë¡œë“œ ì œí•œ ì²´í¬
        if not use_proxy:
            if not download_manager.can_start_download(req.url):
                # ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì •ì§€í•˜ê±°ë‚˜ ì™„ë£Œëœ ê²½ìš°ëŠ” ëŒ€ê¸° ìƒíƒœë¡œ ë³€ê²½í•˜ì§€ ì•ŠìŒ
                db.refresh(req)
                if req.status not in [StatusEnum.stopped, StatusEnum.done]:
                    print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì œí•œì— ê±¸ë¦¼. ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •: ID {request_id}")
                    req.status = StatusEnum.pending
                    db.commit()
                else:
                    print(f"[LOG] ë‹¤ìš´ë¡œë“œê°€ ì •ì§€ ìƒíƒœì´ë¯€ë¡œ ì œí•œ í™•ì¸ ìƒëµ: ID {request_id}")
                    return
                
                    # WebSocketìœ¼ë¡œ ëŒ€ê¸° ìƒíƒœ ì•Œë¦¼
                    send_websocket_message("status_update", {
                        "id": req.id,
                        "url": req.url,
                        "file_name": req.file_name,
                        "status": "pending", 
                        "message": "ë‹¤ìš´ë¡œë“œ ëŒ€ê¸° ì¤‘",
                        "requested_at": req.requested_at.isoformat() if req.requested_at else None
                    })
                
                # ë§¤ë‹ˆì €ê°€ ìë™ìœ¼ë¡œ ì‹œì‘í•´ì£¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ê·¸ëƒ¥ ì¢…ë£Œ
                print(f"[LOG] ë§¤ë‹ˆì €ì˜ ìë™ ì‹œì‘ ê¸°ëŠ¥ì— ì˜í•´ ëŒ€ê¸°: ID {request_id}")
                return
        
        # ë‹¤ìš´ë¡œë“œ ë“±ë¡ (ì œí•œì— ê±¸ë¦¬ì§€ ì•Šì€ ê²½ìš°ë§Œ)
        download_manager.register_download(request_id, req.url)
        
        
        # ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì„¤ì •
        download_path = get_download_path()
        
        # â˜… ë””ë²„ê·¸: íŒŒì¼ëª… ìƒíƒœ í™•ì¸
        # DBì—ì„œ ìµœì‹  ìƒíƒœ ìƒˆë¡œê³ ì¹¨ (íŒŒì¼ëª…ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆì„ ìˆ˜ ìˆìŒ)
        db.refresh(req)
        
        print(f"[DEBUG] ë‹¤ìš´ë¡œë“œ ì‹¤í–‰ ì „ req.file_name (ìƒˆë¡œê³ ì¹¨ í›„): '{req.file_name}'")
        print(f"[DEBUG] req.file_name íƒ€ì…: {type(req.file_name)}")
        print(f"[DEBUG] req.file_nameì´ Noneì¸ê°€: {req.file_name is None}")
        print(f"[DEBUG] req.file_nameì´ ë¹ˆ ë¬¸ìì—´ì¸ê°€: {req.file_name == '' if req.file_name else 'N/A'}")
        print(f"[DEBUG] req.file_name.strip()ì´ ë¹„ì–´ìˆë‚˜: {req.file_name.strip() == '' if req.file_name else 'N/A'}")
        
        # DBì—ì„œ ê°€ì ¸ì˜¨ íŒŒì¼ëª…ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ fallback
        print(f"[CRITICAL_DEBUG] === íŒŒì¼ëª… ê²°ì • ë¡œì§ ===")
        print(f"[CRITICAL_DEBUG] request_id: {request_id}")
        print(f"[CRITICAL_DEBUG] req.file_name ì›ë³¸: '{req.file_name}' (type: {type(req.file_name)})")
        print(f"[CRITICAL_DEBUG] req.file_name is None: {req.file_name is None}")
        print(f"[CRITICAL_DEBUG] req.file_name == '': {req.file_name == '' if req.file_name is not None else 'N/A'}")
        if req.file_name:
            print(f"[CRITICAL_DEBUG] req.file_name.strip(): '{req.file_name.strip()}' (ê¸¸ì´: {len(req.file_name.strip())})")
            print(f"[CRITICAL_DEBUG] req.file_name.strip() == '': {req.file_name.strip() == ''}")
        print(f"[CRITICAL_DEBUG] ì¡°ê±´ (req.file_name and req.file_name.strip()): {bool(req.file_name and req.file_name.strip())}")
        
        if req.file_name and req.file_name.strip():
            base_filename = req.file_name.strip()
            print(f"[LOG] â˜…â˜…â˜… DBì—ì„œ ê°€ì ¸ì˜¨ íŒŒì¼ëª… ì‚¬ìš©: '{base_filename}' â˜…â˜…â˜…")
        else:
            base_filename = f"1fichier_{request_id}.unknown"
            print(f"[LOG] â˜…â˜…â˜… DBì— íŒŒì¼ëª…ì´ ì—†ì–´ì„œ fallback ì‚¬ìš©: '{base_filename}' â˜…â˜…â˜…")
            print(f"[CRITICAL_DEBUG] === ì´ ê²½ìš°ëŠ” ì‚¬ì „íŒŒì‹± ì‹¤íŒ¨ë¥¼ ì˜ë¯¸í•¨! ===")
        print(f"[DEBUG] ê²°ì •ëœ base_filename: '{base_filename}'")
        
        # Windowsì—ì„œ íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±° (ê°„ë‹¨í•˜ê²Œ)
        safe_filename = re.sub(r'[<>:"/\\|?*]', '_', base_filename)
        safe_filename = safe_filename.strip('. ')  # ì•ë’¤ ê³µë°±ê³¼ ì  ì œê±°
        
        # ë¹ˆ íŒŒì¼ëª… ë°©ì§€ (ì‹¤ì œ íŒŒì¼ëª…ì´ ì—†ëŠ” ê²½ìš°ë§Œ)
        if not safe_filename:
            safe_filename = f"1fichier_{request_id}.unknown"
            print(f"[DEBUG] ë¹ˆ íŒŒì¼ëª… ë°©ì§€ë¡œ fallback: '{safe_filename}'")
            
        print(f"[LOG] ì›ë³¸ íŒŒì¼ëª…: '{base_filename}', ì•ˆì „í•œ íŒŒì¼ëª…: '{safe_filename}'")
        
        # ì¤‘ë³µ íŒŒì¼ëª… ë°©ì§€
        final_path = get_unique_filepath(download_path / safe_filename)
        
        file_path = final_path
        part_file_path = download_path / (final_path.name + ".part")
        
        # DBì— ì €ì¥ ê²½ë¡œ ì—…ë°ì´íŠ¸
        req.save_path = str(file_path)
        db.commit()
        print(f"[LOG] ì €ì¥ ê²½ë¡œ ì„¤ì •: {file_path}")
        
        # ê¸°ì¡´ íŒŒì¼ í™•ì¸
        initial_downloaded_size = 0
        if part_file_path.exists():
            file_path = part_file_path
            initial_downloaded_size = part_file_path.stat().st_size
            print(f"[LOG] ì´ì–´ë°›ê¸°: {initial_downloaded_size} bytes")
        elif file_path.exists():
            initial_downloaded_size = file_path.stat().st_size
            print(f"[LOG] ê¸°ì¡´ íŒŒì¼ ë°œê²¬: {initial_downloaded_size} bytes")
        else:
            file_path = part_file_path
            print(f"[LOG] ìƒˆ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        
        # ì •ì§€ ìƒíƒœ ì¬ì²´í¬
        db.refresh(req)
        if req.status == StatusEnum.stopped:
            print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì •ì§€ë¨ (íŒŒì‹± ì‹œì‘ ì „): ID {request_id}")
            return
        
        # 1ë‹¨ê³„: Direct Link íŒŒì‹±
        direct_link = None
        used_proxy_addr = None
        
        if use_proxy:
            print(f"[LOG] í”„ë¡ì‹œ ëª¨ë“œë¡œ ë‹¤ìš´ë¡œë“œ ë§í¬ íŒŒì‹± ì‹œì‘")
            req.status = StatusEnum.proxying
            db.commit()
            
            # WebSocketìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì•Œë¦¼
            send_websocket_message("status_update", {
                "id": req.id,
                "url": req.url,
                "file_name": req.file_name,
                "status": "proxying",
                "error": None
            })
            force_reparse = initial_downloaded_size > 0 or req.direct_link is None
            print(f"[LOG] ê°•ì œ ì¬íŒŒì‹± ëª¨ë“œ: {force_reparse} (ì´ì–´ë°›ê¸°: {initial_downloaded_size > 0}, ë§í¬ì—†ìŒ: {req.direct_link is None})")
            direct_link, used_proxy_addr = parse_with_proxy_cycling(req, db, force_reparse=force_reparse)
        else:
            print(f"[LOG] ë¡œì»¬ ëª¨ë“œë¡œ Direct Link íŒŒì‹±")
            req.status = StatusEnum.downloading
            db.commit()
            
            # WebSocketìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì•Œë¦¼ 
            send_websocket_message("status_update", {
                "id": req.id,
                "url": req.url,
                "file_name": req.file_name,
                "status": "downloading",
                "error": None
            })
            
            # ì¬ì‹œë„ì´ê±°ë‚˜ ì´ì–´ë°›ê¸°ì¸ ê²½ìš° í•­ìƒ ê°•ì œ ì¬íŒŒì‹± (ì›ë³¸ URLë¡œ ìƒˆë¡œ íŒŒì‹±)
            force_reparse = initial_downloaded_size > 0 or req.direct_link is None
            print(f"[LOG] ê°•ì œ ì¬íŒŒì‹± ëª¨ë“œ: {force_reparse} (ì´ì–´ë°›ê¸°: {initial_downloaded_size > 0}, ë§í¬ì—†ìŒ: {req.direct_link is None})")
            
            # ë¡œì»¬ ëª¨ë“œì—ì„œëŠ” íŒŒì¼ ì •ë³´ì™€ í•¨ê»˜ íŒŒì‹±
            from .parser_service import parse_direct_link_with_file_info
            print(f"[LOG] parse_direct_link_with_file_info ì‹œì‘: {req.url}")
            direct_link, file_info = parse_direct_link_with_file_info(
                req.url, req.password, use_proxy=False
            )
            print(f"[LOG] parse_direct_link_with_file_info ê²°ê³¼: direct_link={direct_link}, file_info={file_info}")
            
            # íŒŒì¼ ì •ë³´ê°€ ì¶”ì¶œë˜ë©´ DBì— ì €ì¥ (ë¨¼ì € ì²˜ë¦¬í•˜ì—¬ íŒŒì¼ëª… ë³´ì¡´)
            if file_info and file_info['name'] and (not req.file_name or req.file_name.strip() == ''):
                req.file_name = file_info['name']
                print(f"[LOG] íŒŒì¼ëª… ì¶”ì¶œ: {file_info['name']}")
                db.commit()
            
            # íŒŒì¼ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ íŒŒì‹± ë¡œì§ ì‚¬ìš© (ë‹¨, íŒŒì¼ëª…ì€ ë³´ì¡´)
            if not direct_link:
                print(f"[LOG] Direct Link ì‹¤íŒ¨. ê¸°ì¡´ íŒŒì‹± ë¡œì§ìœ¼ë¡œ ì¬ì‹œë„ (íŒŒì¼ëª… ë³´ì¡´)")
                direct_link = get_or_parse_direct_link(req, use_proxy=False, force_reparse=force_reparse)
                
                # WebSocketìœ¼ë¡œ íŒŒì¼ëª… ì—…ë°ì´íŠ¸ ì „ì†¡
                send_websocket_message("filename_update", {
                    "id": req.id,
                    "file_name": req.file_name,
                    "url": req.url,
                    "status": req.status.value if hasattr(req.status, 'value') else str(req.status)
                })
            
        
        # íŒŒì‹± ì™„ë£Œ í›„ íŒŒì¼ëª… í™•ì¸ (í”„ë¡ì‹œ/ë¡œì»¬ ê³µí†µ)
        print(f"[LOG] íŒŒì‹± ì™„ë£Œ í›„ íŒŒì¼ëª… ì²´í¬: req.file_name='{req.file_name}', type={type(req.file_name)}, len={len(req.file_name) if req.file_name else 'None'}")
        print(f"[LOG] íŒŒì¼ëª… ì¡°ê±´ ì²´í¬: not req.file_name={not req.file_name}, strip()==''{req.file_name.strip() == '' if req.file_name else 'N/A'}, equals_cloud_storage={req.file_name == '1fichier.com: Cloud Storage' if req.file_name else 'N/A'}")
        
        # íŒŒì¼ëª…ì´ ì—†ê±°ë‚˜ ê¸°ë³¸ê°’ì¸ ê²½ìš° fallback ë¡œì§ ì‹œë„ (fallbackì€ ìµœì†Œí™”)
        if not req.file_name or req.file_name.strip() == '' or req.file_name == '1fichier.com: Cloud Storage':
            print(f"[WARNING] íŒŒì‹±ëœ íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤. fallback ë¡œì§ ì‹œì‘")
            
            # URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ ì‹œë„
            from urllib.parse import urlparse, unquote
            parsed_url = urlparse(req.url)
            url_filename = None
            
            # URL ê²½ë¡œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
            if parsed_url.path and '/' in parsed_url.path:
                url_filename = unquote(parsed_url.path.split('/')[-1])
                if url_filename and len(url_filename) > 3 and '.' in url_filename:
                    print(f"[LOG] URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ: '{url_filename}'")
                    req.file_name = url_filename
                    db.commit()
            
            # ì—¬ì „íˆ íŒŒì¼ëª…ì´ ì—†ë‹¤ë©´ ì„ì‹œ íŒŒì¼ëª… ì‚¬ìš© (ë‹¤ìš´ë¡œë“œ ì¤‘ Content-Dispositionì—ì„œ ì—…ë°ì´íŠ¸ë¨)
            if not req.file_name or req.file_name.strip() == '' or req.file_name == '1fichier.com: Cloud Storage':
                print(f"[WARNING] íŒŒì¼ëª…ì„ í™•ì •í•  ìˆ˜ ì—†ì–´ ì„ì‹œëª… ì‚¬ìš© - Content-Dispositionì—ì„œ ì¶”ì¶œ ì‹œë„")
                req.file_name = f"1fichier_{req.id}.tmp"  # ì„ì‹œ íŒŒì¼ëª… ì„¤ì •
                db.commit()
        else:
            print(f"[LOG] íŒŒì‹±ëœ íŒŒì¼ëª… ì‚¬ìš©: '{req.file_name}'")

        # íŒŒì¼ëª…ì´ ì—…ë°ì´íŠ¸ëœ ê²½ìš° ì €ì¥ ê²½ë¡œë„ ë‹¤ì‹œ ì„¤ì •
        # ì¡°ê±´: ì‹¤ì œ íŒŒì¼ëª…ì´ ìˆê³ , í˜„ì¬ ì €ì¥ ê²½ë¡œê°€ ì„ì‹œ íŒŒì¼ëª…ì„ ì‚¬ìš©í•˜ê³  ìˆëŠ” ê²½ìš°
        current_save_path = req.save_path or ""
        is_temp_path = ('.unknown' in current_save_path or '1fichier_' in current_save_path)
        has_real_filename = (req.file_name and req.file_name.strip() and 
                           not req.file_name.startswith('1fichier_') and 
                           not req.file_name.endswith('.tmp') and
                           not req.file_name.endswith('.unknown'))
        
        if has_real_filename and (is_temp_path or not current_save_path):
            print(f"[LOG] ì„ì‹œ ê²½ë¡œì—ì„œ ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ê²½ë¡œ ì¬ì„¤ì •: '{req.file_name}'")
            
            # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
            safe_filename = re.sub(r'[<>:"/\\|?*]', '_', req.file_name.strip())
            safe_filename = safe_filename.strip('. ')
            
            # ì¤‘ë³µ íŒŒì¼ëª… ë°©ì§€
            final_path = get_unique_filepath(download_path / safe_filename)
            
            # ì €ì¥ ê²½ë¡œ ì—…ë°ì´íŠ¸
            req.save_path = str(final_path)
            db.commit()
            print(f"[LOG] ì €ì¥ ê²½ë¡œ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {final_path}")

        # ì •ì§€ ìƒíƒœ ì²´í¬ (íŒŒì‹± í›„)
        db.refresh(req)
        if req.status == StatusEnum.stopped:
            print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì •ì§€ë¨ (íŒŒì‹± í›„): ID {request_id}")
            return
        
        # direct_link ìœ íš¨ì„± ì²´í¬ (DNS ì˜¤ë¥˜ ë“±ìœ¼ë¡œ ì¸í•œ ë§Œë£Œëœ ë§í¬ ê°ì§€)
        if direct_link:
            print(f"[LOG] Direct Link ìœ íš¨ì„± ì²´í¬: {direct_link}")
            from .parser_service import is_direct_link_expired
            if is_direct_link_expired(direct_link, use_proxy=use_proxy):
                print(f"[LOG] Direct Link ë§Œë£Œ ê°ì§€ - ê°•ì œ ì¬íŒŒì‹± ì‹œë„: {direct_link}")
                req.direct_link = None
                db.commit()
                
                # ê°•ì œ ì¬íŒŒì‹±
                if use_proxy:
                    direct_link, used_proxy_addr = parse_with_proxy_cycling(req, db, force_reparse=True)
                else:
                    direct_link = get_or_parse_direct_link(req, use_proxy=False, force_reparse=True)
                
                print(f"[LOG] ì¬íŒŒì‹± ê²°ê³¼: {direct_link}")
        
        if not direct_link:
            # URL ìœ íš¨ì„± ì²´í¬ë¥¼ í†µí•œ ë” ìì„¸í•œ ì—ëŸ¬ ë©”ì‹œì§€
            try:
                import requests
                test_response = requests.head(req.url, timeout=5)
                if test_response.status_code == 404:
                    error_msg = "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì‚­ì œë¨ (404 ì—ëŸ¬)"
                elif test_response.status_code == 403:
                    error_msg = "íŒŒì¼ ì ‘ê·¼ì´ ê±°ë¶€ë¨ (403 ì—ëŸ¬)"
                else:
                    error_msg = f"Direct Link íŒŒì‹± ì‹¤íŒ¨ (HTTP {test_response.status_code})"
            except:
                error_msg = "Direct Link íŒŒì‹± ì‹¤íŒ¨ - URLì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŒ"
            
            print(f"[LOG] {error_msg}")
            req.status = StatusEnum.failed
            req.error = error_msg
            db.commit()
            
            # í…”ë ˆê·¸ë¨ ì•Œë¦¼ì€ ì•„ë˜ì—ì„œ ì¬ì‹œë„ ì—¬ë¶€ í™•ì¸ í›„ ì „ì†¡
            
            # WebSocketìœ¼ë¡œ ì‹¤íŒ¨ ìƒíƒœ ì „ì†¡
            send_websocket_message("status_update", {
                "id": req.id,
                "url": req.url,
                "file_name": req.file_name,
                "status": "failed",
                "error": error_msg,
                "downloaded_size": 0,
                "total_size": 0,
                "save_path": None,
                "requested_at": req.requested_at.isoformat() if req.requested_at else None,
                "finished_at": None,
                "password": req.password,
                "direct_link": req.direct_link,
                "use_proxy": req.use_proxy
            })
            
            raise Exception(error_msg)
        
        # íŠ¹ë³„í•œ ë‹¤ìš´ë¡œë“œ ëª¨ë“œ ì²˜ë¦¬
        if direct_link in ["DIRECT_DOWNLOAD_STREAM", "DIRECT_FILE_RESPONSE"]:
            print(f"[LOG] ì§ì ‘ ë‹¤ìš´ë¡œë“œ ëª¨ë“œ: {direct_link}")
            req.direct_link = direct_link
            req.status = StatusEnum.downloading
            db.commit()
            
            # ì‹¤ì œ íŒŒì¼ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ ë‹¤ì‹œ íŒŒì‹± ì‹œë„
            print(f"[LOG] ì‹¤ì œ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•œ ì¬íŒŒì‹± ì‹œë„...")
            try:
                if use_proxy:
                    real_link, used_proxy_addr = parse_with_proxy_cycling(req, db, force_reparse=True)
                    if real_link and real_link not in ["DIRECT_DOWNLOAD_STREAM", "DIRECT_FILE_RESPONSE"]:
                        direct_link = real_link
                        print(f"[LOG] ì¬íŒŒì‹±ìœ¼ë¡œ ì‹¤ì œ ë§í¬ íšë“: {direct_link}")
                    else:
                        print(f"[LOG] ì¬íŒŒì‹± ì‹¤íŒ¨ - ê¸°ë³¸ ë‹¤ìš´ë¡œë“œ ë°©ë²• ì‚¬ìš©")
                else:
                    real_link = get_or_parse_direct_link(req, use_proxy=False, force_reparse=True)
                    if real_link and real_link not in ["DIRECT_DOWNLOAD_STREAM", "DIRECT_FILE_RESPONSE"]:
                        direct_link = real_link
                        print(f"[LOG] ì¬íŒŒì‹±ìœ¼ë¡œ ì‹¤ì œ ë§í¬ íšë“: {direct_link}")
                    else:
                        print(f"[LOG] ì¬íŒŒì‹± ì‹¤íŒ¨ - íŠ¹ë³„ ì²˜ë¦¬ ëª¨ë“œ ìœ ì§€")
            except Exception as e:
                print(f"[LOG] ì¬íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
            
        else:
            print(f"[LOG] Direct Link íšë“: {direct_link}")
            req.direct_link = direct_link
            req.status = StatusEnum.downloading
            db.commit()
            
            # ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì‹œ ì¦‰ì‹œ WebSocket ìƒíƒœ ì—…ë°ì´íŠ¸ (í”„ë¡œê·¸ë ˆìŠ¤ë°” ì¦‰ì‹œ ì‹œì‘)
            send_websocket_message("status_update", {
                "id": req.id,
                "url": req.url,
                "file_name": req.file_name,
                "status": "downloading",
                "error": None,
                "downloaded_size": initial_downloaded_size,
                "total_size": req.total_size or 0,
                "save_path": req.save_path,
                "requested_at": req.requested_at.isoformat() if req.requested_at else None,
                "finished_at": None,
                "password": req.password,
                "direct_link": req.direct_link,
                "use_proxy": req.use_proxy
            })
            
            # ì •ì§€ ìƒíƒœ ì²´í¬ (ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì „)
            db.refresh(req)
            if req.status == StatusEnum.stopped:
                print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì •ì§€ë¨ (ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì „): ID {request_id}")
                return
            
            # 2ë‹¨ê³„: í”„ë¡ì‹œ ìˆœí™˜ìœ¼ë¡œ ì‹¤ì œ ë‹¤ìš´ë¡œë“œ
            if use_proxy:
                print(f"[LOG] í”„ë¡ì‹œ ìˆœí™˜ ë‹¤ìš´ë¡œë“œ ì‹œì‘ (ì‹œì‘ í”„ë¡ì‹œ: {used_proxy_addr})")
                download_with_proxy_cycling(direct_link, file_path, used_proxy_addr, initial_downloaded_size, req, db)
            else:
                print(f"[LOG] ë¡œì»¬ ì—°ê²°ë¡œ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
                download_local(direct_link, file_path, initial_downloaded_size, req, db)
        
        # ì •ì§€ ìƒíƒœ ì²´í¬ (ì™„ë£Œ ì²˜ë¦¬ ì „)
        db.refresh(req)
        if req.status == StatusEnum.stopped:
            print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì •ì§€ë¨ (ì™„ë£Œ ì²˜ë¦¬ ì „): ID {request_id}")
            return
        
        # 3ë‹¨ê³„: ì™„ë£Œ ì²˜ë¦¬
        # íŒŒì¼ ì •ë¦¬ ë¨¼ì € ìˆ˜í–‰ (.part ì œê±°)
        final_file_path = cleanup_download_file(file_path)
        
        # ì‹¤ì œ íŒŒì¼ëª…ì´ ìˆê³  í˜„ì¬ íŒŒì¼ëª…ì´ ì„ì‹œ íŒŒì¼ëª…ì¸ ê²½ìš° ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½
        if (req.file_name and req.file_name.strip() and 
            not req.file_name.startswith('1fichier_') and 
            not req.file_name.endswith('.unknown') and
            final_file_path and '1fichier_' in str(final_file_path)):
            
            try:
                from pathlib import Path
                
                current_path = Path(final_file_path)
                download_dir = current_path.parent
                
                # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
                safe_filename = re.sub(r'[<>:"/\\|?*]', '_', req.file_name.strip())
                safe_filename = safe_filename.strip('. ')
                
                if safe_filename:
                    # ì¤‘ë³µ íŒŒì¼ëª… ë°©ì§€
                    new_final_path = get_unique_filepath(download_dir / safe_filename)
                    
                    # íŒŒì¼ëª… ë³€ê²½
                    os.rename(final_file_path, new_final_path)
                    final_file_path = new_final_path
                    print(f"[LOG] ì„ì‹œ íŒŒì¼ëª…ì—ì„œ ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½: {current_path.name} -> {new_final_path.name}")
                    
            except Exception as e:
                print(f"[LOG] íŒŒì¼ëª… ë³€ê²½ ì‹¤íŒ¨ (ì„ì‹œ íŒŒì¼ëª… ìœ ì§€): {e}")
        
        # DB ì—…ë°ì´íŠ¸
        req.status = StatusEnum.done
        import datetime
        req.finished_at = datetime.datetime.utcnow()
        if final_file_path:
            req.save_path = str(final_file_path)
        db.commit()
        
        # í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ (ì™„ë£Œ)
        unknown_file = get_translations(lang).get("telegram_unknown_file", "ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼")
        
        # íŒŒì¼ í¬ê¸° í¬ë§·íŒ…
        file_size_str = "ì•Œ ìˆ˜ ì—†ìŒ"
        if req.total_size:
            file_size_str = format_file_size(req.total_size)

        # ì‹œê°„ í¬ë§·íŒ…
        import datetime
        requested_time_str = None
        if req.requested_at:
            if lang == "ko":
                # í•œêµ­ì–´ì¼ ë•Œë§Œ KSTë¡œ ë³€í™˜
                kst_requested = req.requested_at + datetime.timedelta(hours=9)
                requested_time_str = kst_requested.strftime("%Y-%m-%d %H:%M:%S")
            else:
                # ì˜ì–´ ë“± ë‹¤ë¥¸ ì–¸ì–´ëŠ” UTC ê·¸ëŒ€ë¡œ í‘œì‹œ
                requested_time_str = req.requested_at.strftime("%Y-%m-%d %H:%M:%S UTC")

        download_time_str = None
        if req.finished_at:
            if lang == "ko":
                # í•œêµ­ì–´ì¼ ë•Œë§Œ KSTë¡œ ë³€í™˜
                kst_finished = req.finished_at + datetime.timedelta(hours=9)
                download_time_str = kst_finished.strftime("%Y-%m-%d %H:%M:%S")
            else:
                # ì˜ì–´ ë“± ë‹¤ë¥¸ ì–¸ì–´ëŠ” UTC ê·¸ëŒ€ë¡œ í‘œì‹œ
                download_time_str = req.finished_at.strftime("%Y-%m-%d %H:%M:%S UTC")
        
        # ì €ì¥ ê²½ë¡œ (ì–¸ì–´ë³„ ê¸°ë³¸ê°’)
        if lang == "ko":
            save_path_str = req.save_path or "ê¸°ë³¸ê²½ë¡œ"
        else:
            save_path_str = req.save_path or "Default path"
        
        send_telegram_notification(
            req.file_name or unknown_file, 
            "done", 
            None, 
            lang,
            file_size=file_size_str,
            download_time=download_time_str,
            save_path=save_path_str,
            requested_time=requested_time_str
        )
        
        # WebSocketìœ¼ë¡œ ì™„ë£Œ ìƒíƒœ ì „ì†¡
        send_websocket_message("status_update", {
            "id": req.id,
            "url": req.url,
            "file_name": req.file_name,
            "status": "done",
            "error": None,
            "downloaded_size": req.downloaded_size or 0,
            "total_size": req.total_size or 0,
            "progress": 100.0,  # ì™„ë£Œ ì‹œ ëª…ì‹œì ìœ¼ë¡œ 100% ì„¤ì •
            "save_path": req.save_path,
            "requested_at": req.requested_at.isoformat() if req.requested_at else None,
            "finished_at": req.finished_at.isoformat() if req.finished_at else None,
            "password": req.password,
            "direct_link": req.direct_link,
            "use_proxy": req.use_proxy
        })
        
        print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {req.file_name}")
        
    except Exception as e:
        error_str = str(e)
        print(f"[ERROR] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {error_str}")
        print(f"[DEBUG] ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
        print(f"[DEBUG] ì—ëŸ¬ ì„¸ë¶€ì‚¬í•­: {repr(e)}")
        
        if req:
            # ì •ì§€ ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
            db.refresh(req)
            if req.status != StatusEnum.stopped:
                # ì¬ì‹œë„ ë¡œì§ í™•ì¸  
                error_str = str(e)
                should_retry = should_retry_download(retry_count, error_str)
                print(f"[LOG] ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •: {should_retry} (í˜„ì¬ ì¬ì‹œë„: {retry_count})")
                
                # ì™„ë£Œëœ ë‹¤ìš´ë¡œë“œëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
                if should_retry and req.status != StatusEnum.done:
                    new_retry_count = retry_count + 1
                    req.status = StatusEnum.pending  # ë‹¤ì‹œ ëŒ€ê¸° ìƒíƒœë¡œ
                    
                    # 5ë²ˆ ì´í›„ë¶€í„°ëŠ” 3ë¶„(180ì´ˆ) ì§€ì—° ì¶”ê°€
                    import datetime
                    current_time = datetime.datetime.utcnow()
                    if new_retry_count > 5:
                        delay_until = current_time + datetime.timedelta(minutes=3)
                        req.error = f"ì¬ì‹œë„ {new_retry_count} (3ë¶„ ì§€ì—° í›„ ì¬ì‹œë„): {str(e)} | delay_until:{delay_until.isoformat()}"
                        print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì¬ì‹œë„ ì˜ˆì•½ (3ë¶„ ì§€ì—°): {new_retry_count} - {delay_until.isoformat()}")
                    else:
                        req.error = f"ì¬ì‹œë„ {new_retry_count}: {str(e)}"
                        print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì¬ì‹œë„ ì˜ˆì•½: {new_retry_count}")
                    
                    db.commit()
                    
                    # WebSocketìœ¼ë¡œ ì¬ì‹œë„ ìƒíƒœ ì „ì†¡
                    send_websocket_message("status_update", {
                        "id": req.id,
                        "url": req.url,
                        "file_name": req.file_name,
                        "status": "pending",
                        "error": req.error,
                        "downloaded_size": req.downloaded_size or 0,
                        "total_size": req.total_size or 0,
                        "progress": 0.0,  # ì¬ì‹œë„ ì‹œ ì§„í–‰ë¥  ì´ˆê¸°í™”
                        "save_path": req.save_path,
                        "requested_at": req.requested_at.isoformat() if req.requested_at else None,
                        "finished_at": None,
                        "password": req.password,
                        "direct_link": req.direct_link,
                        "use_proxy": req.use_proxy
                    })
                    
                    # 3ì´ˆ í›„ ì¬ì‹œë„ë¥¼ ìœ„í•´ ìƒíƒœë¥¼ pendingìœ¼ë¡œ ë³€ê²½ (ë§¤ë‹ˆì €ê°€ ìë™ìœ¼ë¡œ ì‹œì‘í•˜ë„ë¡)
                    print(f"[LOG] 3ì´ˆ í›„ ìë™ ì¬ì‹œë„ë¥¼ ìœ„í•´ ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •: ID {request_id}")
                    # ì¬ì‹œë„ ìŠ¤ë ˆë“œë¥¼ ì§ì ‘ ìƒì„±í•˜ì§€ ì•Šê³  ë§¤ë‹ˆì €ì˜ ìë™ ì‹œì‘ ê¸°ëŠ¥ ì‚¬ìš©
                    
                else:
                    # 1fichier ìë™ ì¬ì‹œë„ ì²´í¬ (íŒŒì¼ëª…ê³¼ ìš©ëŸ‰ì´ ìˆìœ¼ë©´)
                    # ë‹¨, ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì •ì§€í•œ ê²½ìš°ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
                    db.refresh(req)
                    if (req.status != StatusEnum.stopped and req.status != StatusEnum.done and 
                        should_1fichier_auto_retry(req.url, req.file_name, req.file_size, fichier_retry_count, str(e))):
                        new_fichier_retry_count = fichier_retry_count + 1
                        print(f"[LOG] 1fichier ìë™ ì¬ì‹œë„ ì‹œì‘: {new_fichier_retry_count}/10")
                        
                        # ìƒíƒœë¥¼ pendingìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ëŒ€ê¸° ì¤‘ì„ì„ í‘œì‹œ
                        req.status = StatusEnum.pending
                        
                        # 5ë²ˆ ì´í›„ë¶€í„°ëŠ” 3ë¶„(180ì´ˆ) ì§€ì—° ì¶”ê°€
                        import datetime
                        current_time = datetime.datetime.utcnow()
                        if new_fichier_retry_count > 5:
                            delay_until = current_time + datetime.timedelta(minutes=3)
                            req.error = f"1fichier ìë™ ì¬ì‹œë„ ì¤‘ ({new_fichier_retry_count}/10, 3ë¶„ ì§€ì—° í›„ ì¬ì‹œë„) - {str(e)} | delay_until:{delay_until.isoformat()}"
                            print(f"[LOG] 1fichier ìë™ ì¬ì‹œë„ (3ë¶„ ì§€ì—°): {new_fichier_retry_count}/10 - {delay_until.isoformat()}")
                        else:
                            req.error = f"1fichier ìë™ ì¬ì‹œë„ ì¤‘ ({new_fichier_retry_count}/10) - {str(e)}"
                        
                        db.commit()
                        
                        # WebSocketìœ¼ë¡œ ì¬ì‹œë„ ëŒ€ê¸° ìƒíƒœ ì „ì†¡
                        send_websocket_message("status_update", {
                            "id": req.id,
                            "url": req.url,
                            "file_name": req.file_name,
                            "status": "pending",
                            "error": req.error,
                            "downloaded_size": req.downloaded_size or 0,
                            "total_size": req.total_size or 0,
                            "progress": 0.0,
                            "save_path": req.save_path,
                            "requested_at": req.requested_at.isoformat() if req.requested_at else None,
                            "finished_at": None,
                            "password": req.password,
                            "direct_link": req.direct_link,
                            "use_proxy": req.use_proxy
                        })
                        
                        # 3ë¶„ í›„ ìë™ ì¬ì‹œë„ë¥¼ ìœ„í•´ ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •
                        print(f"[LOG] 3ë¶„ í›„ 1fichier ìë™ ì¬ì‹œë„ë¥¼ ìœ„í•´ ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •: ID {request_id}")
                        # ë§¤ë‹ˆì €ê°€ ì¿¨ë‹¤ìš´ í›„ ìë™ìœ¼ë¡œ ì‹œì‘í•˜ë„ë¡ í•¨
                        
                    else:
                        # ì¬ì‹œë„ í•œë„ ì´ˆê³¼ ë˜ëŠ” ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜
                        req.status = StatusEnum.failed
                        req.error = str(e)
                        db.commit()
                        
                        # í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ (ìµœì¢… ì‹¤íŒ¨)  
                        unknown_file = get_translations(lang).get("telegram_unknown_file", "ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼")
                        
                        # íŒŒì¼ í¬ê¸° í¬ë§·íŒ…
                        file_size_str = "ì•Œ ìˆ˜ ì—†ìŒ"
                        if req.total_size:
                            if req.total_size >= 1024*1024*1024:  # GB
                                file_size_str = f"{req.total_size/(1024*1024*1024):.2f} GB"
                            elif req.total_size >= 1024*1024:  # MB
                                file_size_str = f"{req.total_size/(1024*1024):.2f} MB"
                            elif req.total_size >= 1024:  # KB
                                file_size_str = f"{req.total_size/1024:.2f} KB"
                            else:
                                file_size_str = f"{req.total_size} B"
                        
                        send_telegram_notification(
                            req.file_name or unknown_file, 
                            "failed", 
                            str(e), 
                            lang,
                            file_size=file_size_str
                        )
                        
                        # WebSocketìœ¼ë¡œ ì‹¤íŒ¨ ìƒíƒœ ì „ì†¡
                        send_websocket_message("status_update", {
                            "id": req.id,
                            "url": req.url,
                            "file_name": req.file_name,
                            "status": "failed",
                            "error": str(e),
                            "downloaded_size": req.downloaded_size or 0,
                            "total_size": req.total_size or 0,
                            "progress": 0.0,  # ì‹¤íŒ¨ ì‹œ ì§„í–‰ë¥ ì„ 0ìœ¼ë¡œ ì„¤ì •
                            "save_path": req.save_path,
                            "requested_at": req.requested_at.isoformat() if req.requested_at else None,
                            "finished_at": None,
                            "password": req.password,
                            "direct_link": req.direct_link,
                            "use_proxy": req.use_proxy
                        })
                        
                        print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ë¡œ ë§¤ë‹ˆì €ì—ì„œ í•´ì œë¨: {request_id}")
                
            else:
                print(f"[LOG] ë‹¤ìš´ë¡œë“œê°€ ì •ì§€ ìƒíƒœì´ë¯€ë¡œ ì‹¤íŒ¨ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ: ID {request_id}")
    
    finally:
        # active_downloadsì—ì„œ ì œê±° (ì¤‘ë³µ ì‹œì‘ ë°©ì§€ìš©)
        with download_manager._lock:
            download_manager.active_downloads.pop(request_id, None)
            
        # ë‹¤ìš´ë¡œë“œ í•´ì œ - ì™„ë£Œ ì—¬ë¶€ í™•ì¸í•˜ì—¬ ì „ë‹¬
        if req:
            db.refresh(req)
            is_completed = (req.status == StatusEnum.done)  # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œëœ ê²½ìš°ë§Œ True
            is_local_download = not use_proxy and '1fichier.com' in req.url  # 1fichier ë¡œì»¬ ë‹¤ìš´ë¡œë“œì¸ì§€ í™•ì¸
            
            if is_completed and is_local_download:
                print(f"[LOG] 1fichier ë¡œì»¬ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: ID {request_id}, ì¿¨ë‹¤ìš´ ì ìš©")
            
            download_manager.unregister_download(request_id, is_completed=(is_completed and is_local_download))
        
        db.close()


def parse_filename_with_proxy_cycling(req, db: Session):
    """í”„ë¡ì‹œë¥¼ ì‚¬ìš©í•´ì„œ íŒŒì¼ëª…ë§Œ ë¹ ë¥´ê²Œ íŒŒì‹±"""
    from .proxy_manager import get_working_proxy_batch, get_unused_proxies
    from .parser_service import parse_filename_only_with_proxy
    from .i18n import get_message
    
    # í”„ë¡ì‹œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    all_unused_proxies = get_unused_proxies(db)
    if not all_unused_proxies:
        print(f"[LOG] ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡ì‹œê°€ ì—†ìŒ")
        return None
        
    print(f"[LOG] íŒŒì¼ëª… íŒŒì‹±ìš© {len(all_unused_proxies)}ê°œ í”„ë¡ì‹œ í™•ë³´")
    
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ í”„ë¡ì‹œ í…ŒìŠ¤íŠ¸í•´ì„œ ì„±ê³µí•˜ëŠ” ê²ƒ ì°¾ê¸°
    batch_size = 6
    proxy_index = 0
    
    while proxy_index < len(all_unused_proxies):
        if req.status == StatusEnum.stopped:
            print(f"[LOG] íŒŒì¼ëª… íŒŒì‹±ì´ ì •ì§€ëœ ìƒíƒœ: ID {req.id}")
            return None
            
        batch_end = min(proxy_index + batch_size, len(all_unused_proxies))
        current_batch = all_unused_proxies[proxy_index:batch_end]
        
        print(f"[LOG] íŒŒì¼ëª… íŒŒì‹± ë°°ì¹˜ í…ŒìŠ¤íŠ¸ {proxy_index}-{batch_end-1}: {len(current_batch)}ê°œ í”„ë¡ì‹œ")
        
        working_proxies = get_working_proxy_batch(current_batch)
        if not working_proxies:
            print(f"[LOG] ì´ ë°°ì¹˜ì—ì„œ ì‘ë™í•˜ëŠ” í”„ë¡ì‹œ ì—†ìŒ")
            proxy_index = batch_end
            continue
            
        print(f"[LOG] {len(working_proxies)}ê°œì˜ ê²€ì¦ëœ í”„ë¡ì‹œë¡œ íŒŒì¼ëª… íŒŒì‹± ì‹œë„")
        
        # ê²€ì¦ëœ í”„ë¡ì‹œë“¤ë¡œ íŒŒì¼ëª… íŒŒì‹± ì‹œë„
        for proxy_addr in working_proxies:
            if req.status == StatusEnum.stopped:
                return None
                
            try:
                print(f"[LOG] í”„ë¡ì‹œ {proxy_addr}ë¡œ íŒŒì¼ëª… íŒŒì‹± ì‹œë„")
                result = parse_filename_only_with_proxy(req.url, req.password, proxy_addr)
                if result and result.get('filename'):
                    print(f"[LOG] âœ… íŒŒì¼ëª… íŒŒì‹± ì„±ê³µ: {result['filename']} (í”„ë¡ì‹œ: {proxy_addr})")
                    return result
                    
            except Exception as e:
                print(f"[LOG] âŒ íŒŒì¼ëª… íŒŒì‹± ì‹¤íŒ¨ (í”„ë¡ì‹œ: {proxy_addr}): {e}")
                continue
                
        proxy_index = batch_end
        
    print(f"[LOG] âŒ ëª¨ë“  í”„ë¡ì‹œë¡œ íŒŒì¼ëª… íŒŒì‹± ì‹¤íŒ¨")
    return None

def parse_with_proxy_cycling(req, db: Session, force_reparse=False):
    """í”„ë¡ì‹œ ë°°ì¹˜ë¥¼ ë³‘ë ¬ í…ŒìŠ¤íŠ¸í•´ì„œ ì„±ê³µí•œ í”„ë¡ì‹œë“¤ë¡œ íŒŒì‹±"""
    from .proxy_manager import get_working_proxy_batch, get_unused_proxies
    from .i18n import get_message
    from .shared import download_manager
    
    # í™œì„± ë‹¤ìš´ë¡œë“œ ê°„ì„­ ë°©ì§€ - ì´ë¯¸ ë‹¤ìš´ë¡œë“œê°€ ì§„í–‰ ì¤‘ì¸ ê²½ìš° ìƒíƒœ ë³€ê²½í•˜ì§€ ì•ŠìŒ
    is_actively_downloading = download_manager.is_download_active(req.id)
    if is_actively_downloading:
        print(f"[LOG] ID {req.id}ëŠ” ì´ë¯¸ í™œì„± ë‹¤ìš´ë¡œë“œ ì¤‘ì´ë¯€ë¡œ íŒŒì‹± ìƒíƒœ ë³€ê²½ ìƒëµ")
    else:
        # í”„ë¡ì‹œ íŒŒì‹± ì‹œì‘ ìƒíƒœ ì•Œë¦¼  
        req.status = StatusEnum.parsing
        db.commit()
        
        send_websocket_message("status_update", {
            "id": req.id,
            "status": "parsing",
            "message": get_message("proxy_parsing_started"),
            "progress": 0,
            "url": req.url
        })
    
    # í”„ë¡ì‹œ ëª©ë¡ í•œ ë²ˆë§Œ ê°€ì ¸ì™€ì„œ ìºì‹œ
    all_unused_proxies = get_unused_proxies(db)
    if not all_unused_proxies:
        print(f"[LOG] ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡ì‹œê°€ ì—†ìŒ")
        return None, None
        
    print(f"[LOG] ì´ {len(all_unused_proxies)}ê°œ í”„ë¡ì‹œ ìºì‹œë¨")
    
    # í”„ë¡ì‹œê°€ ë‹¤ ì†Œì§„ë  ë•Œê¹Œì§€ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê³„ì† ì‹œë„
    batch_size = 10
    batch_num = 0
    proxy_index = 0
    
    while True:
        batch_num += 1
        print(f"[LOG] í”„ë¡ì‹œ ë°°ì¹˜ {batch_num} í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ìƒíƒœ ì•Œë¦¼ (í™œì„± ë‹¤ìš´ë¡œë“œ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ)
        if not download_manager.is_download_active(req.id):
            send_websocket_message("status_update", {
                "id": req.id,
                "status": "parsing",
                "message": get_message("proxy_batch_testing").format(batch=batch_num),
                "progress": 5,
                "url": req.url
            })
        
        # ì •ì§€ ìƒíƒœ ì²´í¬
        db.refresh(req)
        if req.status == StatusEnum.stopped:
            print(f"[LOG] í”„ë¡ì‹œ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì¤‘ ì •ì§€ë¨: {req.id}")
            return None, None
        
        # í˜„ì¬ ë°°ì¹˜ì— ì‚¬ìš©í•  í”„ë¡ì‹œë“¤ ì„ íƒ
        batch_proxies = all_unused_proxies[proxy_index:proxy_index + batch_size]
        
        if not batch_proxies:
            print(f"[LOG] ëª¨ë“  í”„ë¡ì‹œê°€ ì†Œì§„ë¨ - ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì¢…ë£Œ")
            break
            
        print(f"[LOG] ë°°ì¹˜ {batch_num}: {len(batch_proxies)}ê°œ í”„ë¡ì‹œ í…ŒìŠ¤íŠ¸")
        
        # ë°°ì¹˜ í”„ë¡ì‹œë¥¼ ë³‘ë ¬ í…ŒìŠ¤íŠ¸ (ìºì‹œëœ ëª©ë¡ ì‚¬ìš©)
        from .proxy_manager import test_proxy_batch, mark_proxy_used
        working_proxies, failed_proxies = test_proxy_batch(db, batch_proxies, req=req)
        
        if working_proxies:
            print(f"[LOG] ë°°ì¹˜ {batch_num}ì—ì„œ {len(working_proxies)}ê°œ í”„ë¡ì‹œ í™•ë³´")
            # ì‹¤íŒ¨í•œ í”„ë¡ì‹œë“¤ì„ ì‚¬ìš©ë¨ìœ¼ë¡œ í‘œì‹œ
            for failed_proxy in failed_proxies:
                mark_proxy_used(db, failed_proxy, success=False)
            break
        else:
            print(f"[LOG] ë°°ì¹˜ {batch_num} ì‹¤íŒ¨ - ë‹¤ìŒ ë°°ì¹˜ë¡œ ì´ë™")
            # ì‹¤íŒ¨í•œ í”„ë¡ì‹œë“¤ì„ ì‚¬ìš©ë¨ìœ¼ë¡œ í‘œì‹œ
            for failed_proxy in failed_proxies:
                mark_proxy_used(db, failed_proxy, success=False)
            proxy_index += batch_size
            
            # ë°°ì¹˜ ê°„ ì§€ì—° (ì°¨ë‹¨ ë°©ì§€ìš©)
            import time
            print(f"[LOG] ë°°ì¹˜ ê°„ ì§€ì—° (ì°¨ë‹¨ ë°©ì§€): 2ì´ˆ ëŒ€ê¸°")
            time.sleep(2)
            continue
    
    if not working_proxies:
        print(f"[LOG] ëª¨ë“  í”„ë¡ì‹œë¥¼ ì†Œì§„í–ˆì§€ë§Œ ì‘ë™í•˜ëŠ” í”„ë¡ì‹œë¥¼ ì°¾ì§€ ëª»í•¨")
        return None, None
    
    print(f"[LOG] {len(working_proxies)}ê°œì˜ ê²€ì¦ëœ í”„ë¡ì‹œë¡œ íŒŒì‹± ì‹œë„")
    
    # ì„±ê³µí•œ í”„ë¡ì‹œë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„ (ê°ê° 1íšŒì”©ë§Œ)
    for i, working_proxy in enumerate(working_proxies):
        print(f"[LOG] ê²€ì¦ëœ í”„ë¡ì‹œë¡œ íŒŒì‹± ì‹œë„ {i+1}/{len(working_proxies)}: {working_proxy}")
        
        # ì •ì§€ ìƒíƒœ ì²´í¬
        db.refresh(req)
        if req.status == StatusEnum.stopped:
            print(f"[LOG] í”„ë¡ì‹œ íŒŒì‹± ì¤‘ ì •ì§€ë¨: {req.id}")
            return None, None
        
        try:
            # WebSocketìœ¼ë¡œ í”„ë¡ì‹œ ì‹œë„ ì¤‘ ì•Œë¦¼ (ìƒì„¸)
            send_websocket_message("proxy_trying", {
                "proxy": working_proxy,
                "step": "íŒŒì‹± ì¤‘ (ê²€ì¦ë¨)",
                "current": i + 1,
                "total": len(working_proxies),
                "url": req.url
            })
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸ë„ í•¨ê»˜ (í™œì„± ë‹¤ìš´ë¡œë“œ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ)
            if not download_manager.is_download_active(req.id):
                send_websocket_message("status_update", {
                    "id": req.id,
                    "status": "parsing",
                    "message": get_message("proxy_verified_parsing").format(current=i + 1, total=len(working_proxies)),
                    "progress": 10 + int((i / len(working_proxies)) * 30),  # 10-40% ì§„í–‰ë¥ 
                    "url": req.url
                })
            
            # í”„ë¡ì‹œë¡œ íŒŒì‹± ì‹œë„ (ì¬ì‹œë„ ì—†ì´ 1íšŒë§Œ) - íŒŒì¼ ì •ë³´ë„ í•¨ê»˜ ì¶”ì¶œ
            try:
                from .parser_service import parse_direct_link_with_file_info
                print(f"[LOG] í”„ë¡ì‹œ {working_proxy}ë¡œ 1íšŒ íŒŒì‹± ì‹œë„")
                direct_link, file_info = parse_direct_link_with_file_info(
                    req.url, 
                    req.password, 
                    use_proxy=True, 
                    proxy_addr=working_proxy
                )
                
                # íŒŒì¼ ì •ë³´ê°€ ì¶”ì¶œë˜ë©´ DBì— ì €ì¥ (ê¸°ì¡´ íŒŒì¼ëª…ì´ ì—†ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš°)
                if file_info and file_info['name'] and (not req.file_name or req.file_name.strip() == ''):
                    req.file_name = file_info['name']
                    print(f"[LOG] í”„ë¡ì‹œ ëª¨ë“œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ: {file_info['name']}")
                    db.commit()
                    
                    # WebSocketìœ¼ë¡œ íŒŒì¼ëª… ì—…ë°ì´íŠ¸ ì „ì†¡
                    send_websocket_message("filename_update", {
                        "id": req.id,
                        "file_name": req.file_name,
                        "url": req.url,
                        "status": req.status.value if hasattr(req.status, 'value') else str(req.status)
                    })
            except Exception as e:
                error_msg = str(e)
                # ì¹´ìš´íŠ¸ë‹¤ìš´ ì œí•œì¸ ê²½ìš° í”„ë¡ì‹œ ë¬¸ì œê°€ ì•„ë‹˜
                if "ì¹´ìš´íŠ¸ë‹¤ìš´ ê°ì§€" in error_msg or "countdown" in error_msg.lower():
                    print(f"[LOG] í”„ë¡ì‹œì—ì„œ ì¹´ìš´íŠ¸ë‹¤ìš´ ê°ì§€ - ë‹¤ë¥¸ í”„ë¡ì‹œë“¤ë„ ë™ì¼í•  ê°€ëŠ¥ì„± ë†’ìŒ")
                    # ì¹´ìš´íŠ¸ë‹¤ìš´ ì •ë³´ ì¶”ì¶œ
                    import re
                    countdown_match = re.search(r'(\d+)ì´ˆ', error_msg)
                    if countdown_match:
                        countdown_seconds = int(countdown_match.group(1))
                        print(f"[LOG] ëª¨ë“  í”„ë¡ì‹œì—ì„œ {countdown_seconds}ì´ˆ ëŒ€ê¸° ì˜ˆìƒ")
                    raise e  # ì¹´ìš´íŠ¸ë‹¤ìš´ì€ ì¬ë°œìƒì‹œì¼œì„œ ìƒìœ„ì—ì„œ ì²˜ë¦¬
                else:
                    raise e  # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ê·¸ëŒ€ë¡œ ì „íŒŒ
            
            if direct_link:
                print(f"[LOG] ê²€ì¦ëœ í”„ë¡ì‹œë¡œ íŒŒì‹± ì„±ê³µ: {working_proxy}")
                mark_proxy_used(db, working_proxy, success=True)
                
                # íŒŒì‹± ì™„ë£Œ, í”„ë¡ì‹œ ì—°ê²° ìƒíƒœë¡œ ì „í™˜
                req.status = StatusEnum.proxying
                db.commit()
                
                send_websocket_message("status_update", {
                    "id": req.id,
                    "status": "proxying",
                    "message": get_message("download_proxying") + f" ({working_proxy})",
                    "progress": 50,
                    "url": req.url
                })
                
                return direct_link, working_proxy
                
        except Exception as e:
            print(f"[LOG] ê²€ì¦ëœ í”„ë¡ì‹œ íŒŒì‹± ì‹¤íŒ¨ - {working_proxy}: {e}")
            mark_proxy_used(db, working_proxy, success=False)
    
    # ê²€ì¦ëœ í”„ë¡ì‹œê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš° ì „ì²´ í”„ë¡ì‹œë¡œ í´ë°±
    unused_proxies = get_unused_proxies(db)
    
    if not unused_proxies:
        print(f"[LOG] ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡ì‹œê°€ ì—†ìŒ")
        return None, None
    
    print(f"[LOG] {len(unused_proxies)}ê°œ í”„ë¡ì‹œë¡œ íŒŒì‹± ì‹œë„ (í´ë°±)")
    
    for i, proxy_addr in enumerate(unused_proxies):
        # ë§¤ í”„ë¡ì‹œ ì‹œë„ë§ˆë‹¤ ì •ì§€ ìƒíƒœ ì²´í¬
        db.refresh(req)
        if req.status == StatusEnum.stopped:
            print(f"[LOG] í”„ë¡ì‹œ íŒŒì‹± ì¤‘ ì •ì§€ë¨: {req.id}")
            return None, None
        
        try:
            # print(f"[LOG] íŒŒì‹± ì‹œë„ {i+1}/{len(unused_proxies)}: {proxy_addr}")
            
            # WebSocketìœ¼ë¡œ í”„ë¡ì‹œ ì‹œë„ ì¤‘ ì•Œë¦¼
            send_websocket_message("proxy_trying", {
                "proxy": proxy_addr,
                "step": "íŒŒì‹± ì¤‘",
                "current": i + 1,
                "total": len(unused_proxies),
                "url": req.url
            })
            
            # í”„ë¡ì‹œë¡œ íŒŒì‹± ì‹œë„ (ì¹´ìš´íŠ¸ë‹¤ìš´ ê°ì§€) - íŒŒì¼ ì •ë³´ë„ í•¨ê»˜ ì¶”ì¶œ
            try:
                from .parser_service import parse_direct_link_with_file_info
                direct_link, file_info = parse_direct_link_with_file_info(
                    req.url, 
                    req.password, 
                    use_proxy=True, 
                    proxy_addr=proxy_addr
                )
                
                # íŒŒì¼ ì •ë³´ê°€ ì¶”ì¶œë˜ë©´ DBì— ì €ì¥ (ê¸°ì¡´ íŒŒì¼ëª…ì´ ì—†ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš°)
                if file_info and file_info['name'] and (not req.file_name or req.file_name.strip() == ''):
                    req.file_name = file_info['name']
                    print(f"[LOG] í”„ë¡ì‹œ ëª¨ë“œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ: {file_info['name']}")
                    db.commit()
                    
                    # WebSocketìœ¼ë¡œ íŒŒì¼ëª… ì—…ë°ì´íŠ¸ ì „ì†¡
                    send_websocket_message("filename_update", {
                        "id": req.id,
                        "file_name": req.file_name,
                        "url": req.url,
                        "status": req.status.value if hasattr(req.status, 'value') else str(req.status)
                    })
            except Exception as e:
                error_msg = str(e)
                # ì¹´ìš´íŠ¸ë‹¤ìš´ ì œí•œì¸ ê²½ìš° ëª¨ë“  í”„ë¡ì‹œì—ì„œ ë™ì¼í•  ê²ƒ
                if "ì¹´ìš´íŠ¸ë‹¤ìš´ ê°ì§€" in error_msg or "countdown" in error_msg.lower():
                    print(f"[LOG] í”„ë¡ì‹œ {proxy_addr}ì—ì„œ ì¹´ìš´íŠ¸ë‹¤ìš´ ê°ì§€ - í”„ë¡ì‹œ ìˆœí™˜ ì¤‘ë‹¨")
                    # ì¹´ìš´íŠ¸ë‹¤ìš´ì€ ì „ì²´ì ì¸ ì‚¬ì´íŠ¸ ì œí•œì´ë¯€ë¡œ ë‹¤ë¥¸ í”„ë¡ì‹œ ì‹œë„ ì¤‘ë‹¨
                    raise e
                else:
                    # ì¼ë°˜ì ì¸ í”„ë¡ì‹œ ì˜¤ë¥˜ëŠ” ê³„ì† ì§„í–‰
                    raise e
            
            # íŒŒì‹± ì™„ë£Œ í›„ ì •ì§€ ìƒíƒœ ì²´í¬
            db.refresh(req)
            if req.status == StatusEnum.stopped:
                print(f"[LOG] í”„ë¡ì‹œ íŒŒì‹± ì™„ë£Œ í›„ ì •ì§€ë¨: {req.id}")
                return None, None
            
            if direct_link:
                print(f"[LOG] íŒŒì‹± ì„±ê³µ - í”„ë¡ì‹œ: {proxy_addr}")
                mark_proxy_used(db, proxy_addr, success=True)
                
                # WebSocketìœ¼ë¡œ í”„ë¡ì‹œ ì„±ê³µ ì•Œë¦¼
                send_websocket_message("proxy_success", {
                    "proxy": proxy_addr,
                    "step": "íŒŒì‹± ì™„ë£Œ",
                    "url": req.url
                })
                
                return direct_link, proxy_addr
                
        except (requests.exceptions.ConnectTimeout, 
                requests.exceptions.ReadTimeout, 
                requests.exceptions.Timeout, 
                requests.exceptions.ProxyError) as e:
            
            print(f"[LOG] íŒŒì‹± ì‹¤íŒ¨ - í”„ë¡ì‹œ {proxy_addr}: {e}")
            mark_proxy_used(db, proxy_addr, success=False)
            
            # WebSocketìœ¼ë¡œ í”„ë¡ì‹œ ì‹¤íŒ¨ ì•Œë¦¼
            send_websocket_message("proxy_failed", {
                "proxy": proxy_addr,
                "step": "íŒŒì‹± ì‹¤íŒ¨",
                "error": str(e),
                "url": req.url
            })
            
            continue
            
        except Exception as e:
            print(f"[LOG] íŒŒì‹± ì˜¤ë¥˜ - í”„ë¡ì‹œ {proxy_addr}: {e}")
            mark_proxy_used(db, proxy_addr, success=False)
            
            # WebSocketìœ¼ë¡œ í”„ë¡ì‹œ ì‹¤íŒ¨ ì•Œë¦¼
            send_websocket_message("proxy_failed", {
                "proxy": proxy_addr,
                "step": "íŒŒì‹± ì˜¤ë¥˜",
                "error": str(e),
                "url": req.url
            })
            
            continue
    
    print(f"[LOG] ëª¨ë“  í”„ë¡ì‹œì—ì„œ íŒŒì‹± ì‹¤íŒ¨")
    return None, None


def download_with_proxy_cycling(direct_link, file_path, preferred_proxy, initial_size, req, db):
    """í”„ë¡ì‹œë¥¼ ìˆœí™˜í•˜ë©´ì„œ ë‹¤ìš´ë¡œë“œ - ì‹¤íŒ¨ì‹œ ìë™ìœ¼ë¡œ ë‹¤ìŒ í”„ë¡ì‹œë¡œ ì´ë™"""
    from .proxy_manager import get_unused_proxies, mark_proxy_used
    
    # ì„ í˜¸ í”„ë¡ì‹œë¶€í„° ì‹œì‘í•˜ì—¬ ëª¨ë“  í”„ë¡ì‹œ ì‹œë„
    unused_proxies = get_unused_proxies(db)
    
    # ì„ í˜¸ í”„ë¡ì‹œê°€ ìˆìœ¼ë©´ ë§¨ ì•ì— ë°°ì¹˜
    if preferred_proxy and preferred_proxy not in unused_proxies:
        unused_proxies.insert(0, preferred_proxy)
    elif preferred_proxy and preferred_proxy in unused_proxies:
        # ì„ í˜¸ í”„ë¡ì‹œë¥¼ ë§¨ ì•ìœ¼ë¡œ ì´ë™
        unused_proxies.remove(preferred_proxy)
        unused_proxies.insert(0, preferred_proxy)
    
    if not unused_proxies:
        print("[LOG] ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡ì‹œê°€ ì—†ìŒ")
        req.status = StatusEnum.failed
        req.error = "ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡ì‹œê°€ ì—†ìŒ"
        db.commit()
        return
    
    print(f"[LOG] {len(unused_proxies)}ê°œ í”„ë¡ì‹œë¡œ ë‹¤ìš´ë¡œë“œ ìˆœí™˜ ì‹œë„")
    
    last_error = None
    for i, proxy_addr in enumerate(unused_proxies):
        # ë§¤ í”„ë¡ì‹œ ì‹œë„ë§ˆë‹¤ ì •ì§€ ìƒíƒœ ì²´í¬
        db.refresh(req)
        if req.status == StatusEnum.stopped:
            print(f"[LOG] í”„ë¡ì‹œ ë‹¤ìš´ë¡œë“œ ì¤‘ ì •ì§€ë¨: {req.id}")
            return
        
        try:
            print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì‹œë„ {i+1}/{len(unused_proxies)}: {proxy_addr}")
            
            # WebSocketìœ¼ë¡œ í”„ë¡ì‹œ ì‹œë„ ì¤‘ ì•Œë¦¼
            send_websocket_message("proxy_trying", {
                "proxy": proxy_addr,
                "step": "ë‹¤ìš´ë¡œë“œ ì¤‘",
                "current": i + 1,
                "total": len(unused_proxies),
                "url": req.url
            })
            
            # í”„ë¡ì‹œë¡œ ë‹¤ìš´ë¡œë“œ ì‹œë„
            download_with_proxy(direct_link, file_path, proxy_addr, initial_size, req, db)
            
            # ì„±ê³µí•˜ë©´ í”„ë¡ì‹œ ì„±ê³µ ë§ˆí‚¹í•˜ê³  ì¢…ë£Œ
            mark_proxy_used(db, proxy_addr, success=True)
            print(f"[LOG] í”„ë¡ì‹œ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {proxy_addr}")
            return
            
        except Exception as e:
            last_error = e
            error_str = str(e)
            print(f"[LOG] í”„ë¡ì‹œ {proxy_addr} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {error_str}")
            
            # í”„ë¡ì‹œ ì‹¤íŒ¨ ë§ˆí‚¹
            mark_proxy_used(db, proxy_addr, success=False)
            
            # WebSocketìœ¼ë¡œ í”„ë¡ì‹œ ì‹¤íŒ¨ ì•Œë¦¼
            send_websocket_message("proxy_failed", {
                "proxy": proxy_addr,
                "error": error_str,
                "current": i + 1,
                "total": len(unused_proxies),
                "url": req.url
            })
            
            # ë§ˆì§€ë§‰ í”„ë¡ì‹œê°€ ì•„ë‹ˆë©´ ê³„ì† ì‹œë„
            if i < len(unused_proxies) - 1:
                print(f"[LOG] ë‹¤ìŒ í”„ë¡ì‹œë¡œ ì´ë™: {i+2}/{len(unused_proxies)}")
                continue
    
    # ëª¨ë“  í”„ë¡ì‹œì—ì„œ ì‹¤íŒ¨
    print(f"[LOG] ëª¨ë“  í”„ë¡ì‹œì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
    if last_error:
        raise last_error  # ë§ˆì§€ë§‰ ì—ëŸ¬ë¥¼ ìƒìœ„ë¡œ ì „íŒŒ


def download_with_proxy(direct_link, file_path, proxy_addr, initial_size, req, db):
    """ì§€ì •ëœ í”„ë¡ì‹œë¡œ ë‹¤ìš´ë¡œë“œ"""
    proxies = {
        'http': f'http://{proxy_addr}',
        'https': f'http://{proxy_addr}'
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': '*/*',
        'Accept-Language': 'ko-KR,ko;q=0.9',
        'Connection': 'keep-alive'
    }
    
    if initial_size > 0:
        headers['Range'] = f'bytes={initial_size}-'
        print(f"[LOG] ì´ì–´ë°›ê¸° í—¤ë”: Range={headers['Range']}")
    
    try:
        # ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì „ ì •ì§€ ìƒíƒœ ì²´í¬
        db.refresh(req)
        if req.status == StatusEnum.stopped:
            print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì „ ì •ì§€ë¨: {req.id}")
            return
        
        # WebSocketìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì•Œë¦¼
        send_websocket_message("proxy_trying", {
            "proxy": proxy_addr,
            "step": "ë‹¤ìš´ë¡œë“œ ì¤‘",
            "current": 1,
            "total": 1,
            "url": req.url
        })
        
        with requests.get(direct_link, stream=True, headers=headers, proxies=proxies, timeout=(3, 10)) as response:
            response.raise_for_status()
            
            # ì‘ë‹µ ë°›ì€ í›„ ì •ì§€ ìƒíƒœ ì²´í¬
            db.refresh(req)
            if req.status == StatusEnum.stopped:
                print(f"[LOG] ì‘ë‹µ ë°›ì€ í›„ ì •ì§€ë¨: {req.id}")
                return
            
            content_length = int(response.headers.get('Content-Length', 0))
            content_type = response.headers.get('Content-Type', '').lower()
            
            # Content-Dispositionì—ì„œ ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ ì‹œë„
            content_disposition = response.headers.get('Content-Disposition', '')
            if content_disposition and 'filename' in content_disposition:
                import re
                # filename="..." ë˜ëŠ” filename*=UTF-8''... í˜•íƒœ ì²˜ë¦¬
                filename_match = re.search(r'filename[*]?=(?:UTF-8\'\')?["\']?([^"\';\r\n]*)["\']?', content_disposition)
                if filename_match:
                    extracted_filename = filename_match.group(1).strip()
                    # URL ë””ì½”ë”©
                    from urllib.parse import unquote
                    extracted_filename = unquote(extracted_filename)
                    
                    # ì„ì‹œ íŒŒì¼ëª…ì´ê±°ë‚˜ íŒŒì¼ëª…ì´ í™•ì •ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
                    if (req.file_name.endswith('.tmp') or req.file_name == '1fichier.com: Cloud Storage' or 
                        req.file_name.startswith('1fichier_')):
                        print(f"[LOG] Content-Dispositionì—ì„œ ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ: '{extracted_filename}'")
                        req.file_name = extracted_filename
                        db.commit()
                        
                        # WebSocketìœ¼ë¡œ íŒŒì¼ëª… ì—…ë°ì´íŠ¸ ì „ì†¡
                        send_websocket_message("filename_update", {
                            "id": req.id,
                            "file_name": req.file_name,
                            "url": req.url,
                            "status": req.status.value if hasattr(req.status, 'value') else str(req.status)
                        })
            
            # ì‘ë‹µ ê²€ì¦: HTMLì´ë‚˜ ë¹ˆ íŒŒì¼ì¸ì§€ í™•ì¸
            print(f"[LOG] í”„ë¡ì‹œ ì‘ë‹µ ë¶„ì„ - Content-Length: {content_length}, Content-Type: {content_type}")
            
            # Content-Typeì´ HTMLì¸ ê²½ìš° - ë‚´ìš©ì„ í™•ì¸í•´ì„œ ì‹¤ì œ HTMLì¸ì§€ íŒë‹¨
            if 'text/html' in content_type:
                print(f"[LOG] HTML Content-Type ê°ì§€ - ë‚´ìš© ê²€ì‚¬ ì¤‘...")
                # ì²˜ìŒ 1024ë°”ì´íŠ¸ë¥¼ í™•ì¸í•´ì„œ ì‹¤ì œ HTMLì¸ì§€ íŒë‹¨
                peek_content = response.content[:1024] if hasattr(response, 'content') else b''
                try:
                    peek_text = peek_content.decode('utf-8', errors='ignore').lower()
                    # ì‹¤ì œ HTML íƒœê·¸ì™€ ì—ëŸ¬ ë©”ì‹œì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
                    html_indicators = ['<html', '<body', '<head', '<!doctype']
                    error_indicators = ['error', '404', '403', 'not found', 'access denied', 'forbidden']
                    
                    has_html_tags = any(indicator in peek_text for indicator in html_indicators)
                    has_error_msg = any(indicator in peek_text for indicator in error_indicators)
                    
                    # HTML íƒœê·¸ê°€ ìˆê³  ì—ëŸ¬ ë©”ì‹œì§€ë„ ìˆìœ¼ë©´ ì‹¤ì œ ì—ëŸ¬ í˜ì´ì§€
                    if has_html_tags and has_error_msg:
                        print(f"[LOG] ì‹¤ì œ HTML ì—ëŸ¬ í˜ì´ì§€ ê°ì§€: {peek_text[:100]}...")
                        raise Exception("ë‹¤ìš´ë¡œë“œ ë§í¬ê°€ ì—ëŸ¬ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ë¨ (HTML ì‘ë‹µ)")
                    elif has_html_tags:
                        print(f"[LOG] HTML í˜ì´ì§€ì§€ë§Œ ì—ëŸ¬ê°€ ì•„ë‹ ìˆ˜ ìˆìŒ - ê³„ì† ì§„í–‰")
                    else:
                        print(f"[LOG] HTML Content-Typeì´ì§€ë§Œ ì‹¤ì œ íŒŒì¼ ë°ì´í„°ë¡œ ë³´ì„ - ê³„ì† ì§„í–‰")
                except:
                    print(f"[LOG] HTML ë‚´ìš© ê²€ì‚¬ ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")
                    pass
            
            # Content-Lengthê°€ ë„ˆë¬´ ì‘ì€ ê²½ìš° (1KB ë¯¸ë§Œ)
            if content_length < 1024 and initial_size == 0:
                print(f"[LOG] íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ: {content_length} bytes - ì—ëŸ¬ ì‘ë‹µì¼ ê°€ëŠ¥ì„±")
                # ì‘ì€ ì‘ë‹µì˜ ë‚´ìš©ì„ í™•ì¸í•´ë´„
                peek_content = response.content[:500]  # ì²˜ìŒ 500ë°”ì´íŠ¸ë§Œ í™•ì¸
                try:
                    peek_text = peek_content.decode('utf-8', errors='ignore').lower()
                    # HTML íƒœê·¸ë‚˜ ì—ëŸ¬ ë©”ì‹œì§€ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    error_indicators = ['<html', '<body', 'error', '404', '403', 'not found', 'access denied']
                    if any(indicator in peek_text for indicator in error_indicators):
                        print(f"[LOG] ì‘ë‹µì— ì—ëŸ¬ ë‚´ìš© ê°ì§€: {peek_text[:100]}...")
                        raise Exception(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - ì—ëŸ¬ ì‘ë‹µ ê°ì§€ (í¬ê¸°: {content_length} bytes)")
                except:
                    pass  # ë””ì½”ë”© ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            
            if initial_size > 0:
                # ì´ì–´ë°›ê¸°: ì „ì²´ í¬ê¸° = ê¸°ì¡´ í¬ê¸° + ë‚¨ì€ í¬ê¸°
                total_size = initial_size + content_length
                print(f"[LOG] ì´ì–´ë°›ê¸° - ê¸°ì¡´: {initial_size}, ë‚¨ì€ í¬ê¸°: {content_length}")
            else:
                # ìƒˆ ë‹¤ìš´ë¡œë“œ: ì „ì²´ í¬ê¸° = Content-Length
                total_size = content_length
            
            # íŒŒì¼ í¬ê¸°ê°€ 0ì¸ ê²½ìš° ë‹¤ìš´ë¡œë“œ ì¤‘ë‹¨
            if total_size == 0:
                print(f"[LOG] íŒŒì¼ í¬ê¸°ê°€ 0 - ë‹¤ìš´ë¡œë“œ ì¤‘ë‹¨")
                raise Exception("íŒŒì¼ í¬ê¸°ê°€ 0ì…ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ë§í¬ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
            req.total_size = total_size
            db.commit()
            
            print(f"[LOG] í”„ë¡ì‹œ ë‹¤ìš´ë¡œë“œ ì‹œì‘ - ì´ í¬ê¸°: {total_size} bytes, Content-Type: {content_type}")
            
            # íŒŒì¼ ê²½ë¡œ ê²€ì¦ ë° ë””ë ‰í† ë¦¬ ìƒì„±
            try:
                download_path = Path(file_path).parent
                download_path.mkdir(parents=True, exist_ok=True)
                print(f"[LOG] íŒŒì¼ ì €ì¥ ê²½ë¡œ: {file_path}")
            except Exception as e:
                raise Exception(f"ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            
            try:
                with open(file_path, 'ab' if initial_size > 0 else 'wb') as f:
                    downloaded = initial_size
                    last_update_size = downloaded
                    
                    chunk_count = 0
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            chunk_count += 1
                            
                            # ë§¤ 64KBë§ˆë‹¤(8ê°œ ì²­í¬) ì •ì§€ ìƒíƒœ ì²´í¬
                            if chunk_count % 8 == 0:
                                db.refresh(req)
                                if req.status == StatusEnum.stopped:
                                    print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì¤‘ ì •ì§€ë¨: {req.id} (ì§„í–‰ë¥ : {downloaded}/{total_size})")
                                    return
                            
                            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ - ì ì ˆí•œ ë¹ˆë„ (ë§¤ 512KBë§ˆë‹¤) + WebSocket ì‹¤ì‹œê°„ ì „ì†¡  
                            # ì§„í–‰ë¥  ë° ì†ë„ ê³„ì‚°
                            # ì•ˆì „í•œ ì§„í–‰ë¥  ê³„ì‚° (NaN ë°©ì§€)
                            try:
                                if total_size > 0 and downloaded >= 0:
                                    progress = (downloaded / total_size * 100)
                                    # NaN ì²´í¬
                                    if not (0 <= progress <= 100):
                                        progress = 0.0
                                else:
                                    progress = 0.0
                            except (ZeroDivisionError, TypeError, ValueError):
                                progress = 0.0
                            current_percent_for_log = int(progress // 5) * 5  # 5% ë‹¨ìœ„ (ë¡œê·¸ìš©)
                            current_percent_for_ui = int(progress * 2) / 2  # 0.5% ë‹¨ìœ„ (UI ì—…ë°ì´íŠ¸ìš©)
                            
                            # ì†ë„ ê³„ì‚°ì„ ìœ„í•œ ì‹œê°„ ì¶”ì 
                            current_time = time.time()
                            if not hasattr(req, '_speed_start_time'):
                                req._speed_start_time = current_time
                                req._speed_start_bytes = downloaded
                            
                            if downloaded - last_update_size >= 10485760 or current_percent_for_ui != getattr(req, '_last_ui_percent', 0):  # 10MBë§ˆë‹¤ ë˜ëŠ” 0.5% ë‹¨ìœ„ë¡œ ì—…ë°ì´íŠ¸
                                req.downloaded_size = downloaded
                                db.commit()
                                last_update_size = downloaded
                                
                                # 5% ë‹¨ìœ„ë¡œë§Œ ë¡œê·¸ ì¶œë ¥ (ì†ë„ í¬í•¨)
                                if current_percent_for_log != getattr(req, '_last_logged_percent', 0) and current_percent_for_log % 5 == 0 and current_percent_for_log > 0:
                                    req._last_logged_percent = current_percent_for_log
                                    # ì†ë„ ê³„ì‚° (ë¡œê·¸ìš©)
                                    time_elapsed = current_time - req._speed_start_time
                                    if time_elapsed > 0:
                                        bytes_diff = downloaded - req._speed_start_bytes
                                        download_speed = bytes_diff / time_elapsed
                                        speed_mb = download_speed / (1024 * 1024)
                                        print(f"[LOG] í”„ë¡ì‹œ ì§„í–‰ë¥ : {current_percent_for_log}% ({downloaded}/{total_size}) - ì†ë„: {speed_mb:.2f}MB/s")
                                        req._speed_start_time = current_time
                                        req._speed_start_bytes = downloaded
                                
                                # 0.5% ë‹¨ìœ„ë¡œ WebSocket ì—…ë°ì´íŠ¸ (í™”ë©´ ì—…ë°ì´íŠ¸)
                                if current_percent_for_ui != getattr(req, '_last_ui_percent', 0):
                                    req._last_ui_percent = current_percent_for_ui
                                    
                                    # ì†ë„ëŠ” 2% ë‹¨ìœ„ë¡œë§Œ ì—…ë°ì´íŠ¸ (ë” ì•ˆì •ì )
                                    current_percent_for_speed = int(progress // 2) * 2
                                    download_speed = getattr(req, '_last_download_speed', 0)
                                    
                                    if current_percent_for_speed != getattr(req, '_last_speed_percent', 0):
                                        req._last_speed_percent = current_percent_for_speed
                                        # ì†ë„ ê³„ì‚° (ì²« 1ë¶„ì€ 2ì´ˆ, ì´í›„ 4ì´ˆ ê°„ê²©)
                                        speed_time_elapsed = current_time - getattr(req, '_ui_speed_time', current_time - 4)
                                        download_start_time = getattr(req, '_download_start_time', current_time)
                                        is_initial_phase = (current_time - download_start_time) < 60  # ì²« 1ë¶„
                                        
                                        min_interval = 2.0 if is_initial_phase else 4.0
                                        if speed_time_elapsed >= min_interval or not hasattr(req, '_ui_speed_time'):
                                            speed_bytes_diff = downloaded - getattr(req, '_ui_speed_bytes', downloaded)
                                            if speed_time_elapsed > 0 and speed_bytes_diff > 0:
                                                download_speed = speed_bytes_diff / speed_time_elapsed
                                            elif not hasattr(req, '_ui_speed_time'):
                                                # ì²« ì¸¡ì •ì‹œì—ëŠ” ê¸°ë³¸ê°’
                                                download_speed = 0
                                            req._ui_speed_time = current_time
                                            req._ui_speed_bytes = downloaded
                                            req._last_download_speed = download_speed
                                            if not hasattr(req, '_download_start_time'):
                                                req._download_start_time = current_time
                                    
                                    send_websocket_message("progress_update", {
                                        "id": req.id,
                                        "downloaded_size": downloaded,
                                        "total_size": total_size,
                                        "progress": round(max(0.0, min(100.0, progress or 0.0)), 1),
                                        "download_speed": round(download_speed, 0),
                                        "status": "downloading"
                                    })
                    
                    req.downloaded_size = downloaded
                    db.commit()
                
            except Exception as file_error:
                raise Exception(f"íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨: {file_error}")
                
        print(f"[LOG] í”„ë¡ì‹œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {downloaded} bytes")
        
        # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í›„ íŒŒì¼ ê²€ì¦
        if downloaded == 0:
            print(f"[LOG] ê²½ê³ : ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°ê°€ 0 bytes")
            raise Exception("ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - ë°›ì€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        elif downloaded < 1024:
            print(f"[LOG] ê²½ê³ : ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ë§¤ìš° ì‘ìŒ ({downloaded} bytes)")
            # ì‘ì€ íŒŒì¼ì˜ ë‚´ìš©ì„ í™•ì¸í•´ë´„
            try:
                with open(file_path, 'rb') as check_file:
                    content = check_file.read(500)
                    try:
                        text_content = content.decode('utf-8', errors='ignore').lower()
                        if any(indicator in text_content for indicator in ['<html', 'error', '404', '403']):
                            print(f"[LOG] ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ì—ëŸ¬ í˜ì´ì§€ì„: {text_content[:100]}...")
                            raise Exception(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - ì—ëŸ¬ í˜ì´ì§€ ë°›ìŒ ({downloaded} bytes)")
                    except:
                        pass
            except:
                pass
        
        mark_proxy_used(db, proxy_addr, success=True)
        
        # WebSocketìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ì„±ê³µ ì•Œë¦¼
        send_websocket_message("proxy_success", {
            "proxy": proxy_addr,
            "step": "ë‹¤ìš´ë¡œë“œ ì™„ë£Œ",
            "url": req.url
        })
        
    except Exception as e:
        error_str = str(e)
        print(f"[LOG] í”„ë¡ì‹œ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        mark_proxy_used(db, proxy_addr, success=False)
        
        # DNS ì˜¤ë¥˜ ê°ì§€ ì‹œ ì¬íŒŒì‹± ì‹œë„ (í”„ë¡ì‹œì—ì„œë„)
        if any(dns_error in error_str for dns_error in [
            "NameResolutionError", "Failed to resolve", "Name or service not known", 
            "No address associated with hostname", "nodename nor servname provided"
        ]):
            print(f"[LOG] í”„ë¡ì‹œì—ì„œ DNS í•´ìƒë„ ì˜¤ë¥˜ ê°ì§€ - ë‹¤ìš´ë¡œë“œ ë§í¬ ì¬íŒŒì‹± ì‹œë„")
            print(f"[LOG] ë§Œë£Œëœ ë§í¬: {direct_link}")
            
            try:
                # ê¸°ì¡´ direct_link ì™„ì „ ì´ˆê¸°í™”
                req.direct_link = None
                db.commit()
                
                # ê°•ì œ ì¬íŒŒì‹± ì‹œë„ (ì—¬ëŸ¬ í”„ë¡ì‹œë¡œ ì‹œë„)
                print(f"[LOG] ì›ë³¸ URLë¡œ ê°•ì œ ì¬íŒŒì‹± ì‹œë„: {req.url}")
                new_direct_link, used_proxy = parse_with_proxy_cycling(req, db, force_reparse=True)
                
                if new_direct_link and new_direct_link != direct_link:
                    print(f"[LOG] í”„ë¡ì‹œì—ì„œ DNS ì˜¤ë¥˜ í›„ ì¬íŒŒì‹± ì„±ê³µ: {new_direct_link}")
                    req.direct_link = new_direct_link
                    db.commit()
                    
                    # ì¬íŒŒì‹±ëœ ë§í¬ë¡œ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ ì‹œë„
                    if used_proxy:
                        return download_with_proxy(new_direct_link, file_path, used_proxy, initial_size, req, db)
                    else:
                        return download_local(new_direct_link, file_path, initial_size, req, db)
                else:
                    print(f"[LOG] í”„ë¡ì‹œì—ì„œ DNS ì˜¤ë¥˜ í›„ ì¬íŒŒì‹± ì‹¤íŒ¨ - í”„ë¡ì‹œ ìˆœí™˜ìœ¼ë¡œë„ ìƒˆ ë§í¬ íšë“ ë¶ˆê°€")
                    
            except Exception as reparse_error:
                print(f"[LOG] í”„ë¡ì‹œì—ì„œ DNS ì˜¤ë¥˜ í›„ ì¬íŒŒì‹± ì¤‘ ì˜ˆì™¸: {reparse_error}")
                
                # ë§ˆì§€ë§‰ ì‹œë„: ë¡œì»¬ ì—°ê²°ë¡œ ì¬íŒŒì‹±
                try:
                    print(f"[LOG] ë§ˆì§€ë§‰ ì‹œë„: ë¡œì»¬ ì—°ê²°ë¡œ ì¬íŒŒì‹±")
                    from .parser_service import parse_direct_link_simple
                    local_direct_link = parse_direct_link_simple(req.url, req.password, use_proxy=False)
                    if local_direct_link and local_direct_link != direct_link:
                        print(f"[LOG] ë¡œì»¬ ì—°ê²°ë¡œ ì¬íŒŒì‹± ì„±ê³µ: {local_direct_link}")
                        req.direct_link = local_direct_link
                        db.commit()
                        return download_local(local_direct_link, file_path, initial_size, req, db)
                except Exception as local_error:
                    print(f"[LOG] ë¡œì»¬ ì—°ê²° ì¬íŒŒì‹±ë„ ì‹¤íŒ¨: {local_error}")
        
        # WebSocketìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì•Œë¦¼
        send_websocket_message("proxy_failed", {
            "proxy": proxy_addr,
            "step": "ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨",
            "error": str(e),
            "url": req.url
        })
        
        raise e


def download_local(direct_link, file_path, initial_size, req, db):
    """ë¡œì»¬ ì—°ê²°ë¡œ ë‹¤ìš´ë¡œë“œ"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': '*/*',
        'Accept-Language': 'ko-KR,ko;q=0.9',
        'Connection': 'keep-alive'
    }
    
    if initial_size > 0:
        headers['Range'] = f'bytes={initial_size}-'
        print(f"[LOG] ì´ì–´ë°›ê¸° í—¤ë”: Range={headers['Range']}")
    
    try:
        # ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì „ ì •ì§€ ìƒíƒœ ì²´í¬
        db.refresh(req)
        if req.status == StatusEnum.stopped:
            print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì „ ì •ì§€ë¨: {req.id}")
            return
        
        print(f"[LOG] ë¡œì»¬ ì—°ê²°ë¡œ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        
        with requests.get(direct_link, stream=True, headers=headers, timeout=(10, 30)) as response:
            response.raise_for_status()
            
            # ì‘ë‹µ ë°›ì€ í›„ ì •ì§€ ìƒíƒœ ì²´í¬
            db.refresh(req)
            if req.status == StatusEnum.stopped:
                print(f"[LOG] ì‘ë‹µ ë°›ì€ í›„ ì •ì§€ë¨: {req.id}")
                return
            
            content_length = int(response.headers.get('Content-Length', 0))
            content_type = response.headers.get('Content-Type', '').lower()
            
            # Content-Dispositionì—ì„œ ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ ì‹œë„ (ë¡œì»¬)
            content_disposition = response.headers.get('Content-Disposition', '')
            if content_disposition and 'filename' in content_disposition:
                import re
                # filename="..." ë˜ëŠ” filename*=UTF-8''... í˜•íƒœ ì²˜ë¦¬
                filename_match = re.search(r'filename[*]?=(?:UTF-8\'\')?["\']?([^"\';\r\n]*)["\']?', content_disposition)
                if filename_match:
                    extracted_filename = filename_match.group(1).strip()
                    # URL ë””ì½”ë”©
                    from urllib.parse import unquote
                    extracted_filename = unquote(extracted_filename)
                    
                    # ì„ì‹œ íŒŒì¼ëª…ì´ê±°ë‚˜ íŒŒì¼ëª…ì´ í™•ì •ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
                    if (req.file_name.endswith('.tmp') or req.file_name == '1fichier.com: Cloud Storage' or 
                        req.file_name.startswith('1fichier_')):
                        print(f"[LOG] ë¡œì»¬ Content-Dispositionì—ì„œ ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ: '{extracted_filename}'")
                        req.file_name = extracted_filename
                        db.commit()
                        
                        # WebSocketìœ¼ë¡œ íŒŒì¼ëª… ì—…ë°ì´íŠ¸ ì „ì†¡
                        send_websocket_message("filename_update", {
                            "id": req.id,
                            "file_name": req.file_name,
                            "url": req.url,
                            "status": req.status.value if hasattr(req.status, 'value') else str(req.status)
                        })
            
            # ì‘ë‹µ ê²€ì¦: HTMLì´ë‚˜ ë¹ˆ íŒŒì¼ì¸ì§€ í™•ì¸
            print(f"[LOG] ë¡œì»¬ ì‘ë‹µ ë¶„ì„ - Content-Length: {content_length}, Content-Type: {content_type}")
            
            # Content-Typeì´ HTMLì¸ ê²½ìš° - ë‚´ìš©ì„ í™•ì¸í•´ì„œ ì‹¤ì œ HTMLì¸ì§€ íŒë‹¨
            if 'text/html' in content_type:
                print(f"[LOG] HTML Content-Type ê°ì§€ - ë‚´ìš© ê²€ì‚¬ ì¤‘...")
                # ì²˜ìŒ 1024ë°”ì´íŠ¸ë¥¼ í™•ì¸í•´ì„œ ì‹¤ì œ HTMLì¸ì§€ íŒë‹¨
                peek_content = response.content[:1024] if hasattr(response, 'content') else b''
                try:
                    peek_text = peek_content.decode('utf-8', errors='ignore').lower()
                    # ì‹¤ì œ HTML íƒœê·¸ì™€ ì—ëŸ¬ ë©”ì‹œì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
                    html_indicators = ['<html', '<body', '<head', '<!doctype']
                    error_indicators = ['error', '404', '403', 'not found', 'access denied', 'forbidden']
                    
                    has_html_tags = any(indicator in peek_text for indicator in html_indicators)
                    has_error_msg = any(indicator in peek_text for indicator in error_indicators)
                    
                    # HTML íƒœê·¸ê°€ ìˆê³  ì—ëŸ¬ ë©”ì‹œì§€ë„ ìˆìœ¼ë©´ ì‹¤ì œ ì—ëŸ¬ í˜ì´ì§€
                    if has_html_tags and has_error_msg:
                        print(f"[LOG] ì‹¤ì œ HTML ì—ëŸ¬ í˜ì´ì§€ ê°ì§€: {peek_text[:100]}...")
                        raise Exception("ë‹¤ìš´ë¡œë“œ ë§í¬ê°€ ì—ëŸ¬ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ë¨ (HTML ì‘ë‹µ)")
                    elif has_html_tags:
                        print(f"[LOG] HTML í˜ì´ì§€ì§€ë§Œ ì—ëŸ¬ê°€ ì•„ë‹ ìˆ˜ ìˆìŒ - ê³„ì† ì§„í–‰")
                    else:
                        print(f"[LOG] HTML Content-Typeì´ì§€ë§Œ ì‹¤ì œ íŒŒì¼ ë°ì´í„°ë¡œ ë³´ì„ - ê³„ì† ì§„í–‰")
                except:
                    print(f"[LOG] HTML ë‚´ìš© ê²€ì‚¬ ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")
                    pass
            
            # Content-Lengthê°€ ë„ˆë¬´ ì‘ì€ ê²½ìš° (1KB ë¯¸ë§Œ)
            if content_length < 1024 and initial_size == 0:
                print(f"[LOG] íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ: {content_length} bytes - ì—ëŸ¬ ì‘ë‹µì¼ ê°€ëŠ¥ì„±")
                # ì‘ì€ ì‘ë‹µì˜ ë‚´ìš©ì„ í™•ì¸í•´ë´„
                peek_content = response.content[:500]  # ì²˜ìŒ 500ë°”ì´íŠ¸ë§Œ í™•ì¸
                try:
                    peek_text = peek_content.decode('utf-8', errors='ignore').lower()
                    # HTML íƒœê·¸ë‚˜ ì—ëŸ¬ ë©”ì‹œì§€ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    error_indicators = ['<html', '<body', 'error', '404', '403', 'not found', 'access denied']
                    if any(indicator in peek_text for indicator in error_indicators):
                        print(f"[LOG] ì‘ë‹µì— ì—ëŸ¬ ë‚´ìš© ê°ì§€: {peek_text[:100]}...")
                        raise Exception(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - ì—ëŸ¬ ì‘ë‹µ ê°ì§€ (í¬ê¸°: {content_length} bytes)")
                except:
                    pass  # ë””ì½”ë”© ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            
            if initial_size > 0:
                # ì´ì–´ë°›ê¸°: ì „ì²´ í¬ê¸° = ê¸°ì¡´ í¬ê¸° + ë‚¨ì€ í¬ê¸°
                total_size = initial_size + content_length
                print(f"[LOG] ì´ì–´ë°›ê¸° - ê¸°ì¡´: {initial_size}, ë‚¨ì€ í¬ê¸°: {content_length}")
            else:
                # ìƒˆ ë‹¤ìš´ë¡œë“œ: ì „ì²´ í¬ê¸° = Content-Length
                total_size = content_length
            
            # íŒŒì¼ í¬ê¸°ê°€ 0ì¸ ê²½ìš° ë‹¤ìš´ë¡œë“œ ì¤‘ë‹¨
            if total_size == 0:
                print(f"[LOG] íŒŒì¼ í¬ê¸°ê°€ 0 - ë‹¤ìš´ë¡œë“œ ì¤‘ë‹¨")
                raise Exception("íŒŒì¼ í¬ê¸°ê°€ 0ì…ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ë§í¬ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
            req.total_size = total_size
            db.commit()
            
            print(f"[LOG] ë¡œì»¬ ë‹¤ìš´ë¡œë“œ ì‹œì‘ - ì´ í¬ê¸°: {total_size} bytes, Content-Type: {content_type}")
            
            # íŒŒì¼ ê²½ë¡œ ê²€ì¦ ë° ë””ë ‰í† ë¦¬ ìƒì„±
            try:
                download_path = Path(file_path).parent
                download_path.mkdir(parents=True, exist_ok=True)
                print(f"[LOG] íŒŒì¼ ì €ì¥ ê²½ë¡œ: {file_path}")
            except Exception as e:
                raise Exception(f"ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            
            try:
                with open(file_path, 'ab' if initial_size > 0 else 'wb') as f:
                    downloaded = initial_size
                    last_update_size = downloaded
                    
                    chunk_count = 0
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            chunk_count += 1
                            
                            # ë§¤ 64KBë§ˆë‹¤(8ê°œ ì²­í¬) ì •ì§€ ìƒíƒœ ì²´í¬
                            if chunk_count % 8 == 0:
                                db.refresh(req)
                                if req.status == StatusEnum.stopped:
                                    print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì¤‘ ì •ì§€ë¨: {req.id} (ì§„í–‰ë¥ : {downloaded}/{total_size})")
                                    return
                            
                            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ - ì ì ˆí•œ ë¹ˆë„ (ë§¤ 512KBë§ˆë‹¤) + WebSocket ì‹¤ì‹œê°„ ì „ì†¡  
                            # ì§„í–‰ë¥  ë° ì†ë„ ê³„ì‚°
                            # ì•ˆì „í•œ ì§„í–‰ë¥  ê³„ì‚° (NaN ë°©ì§€)
                            try:
                                if total_size > 0 and downloaded >= 0:
                                    progress = (downloaded / total_size * 100)
                                    # NaN ì²´í¬
                                    if not (0 <= progress <= 100):
                                        progress = 0.0
                                else:
                                    progress = 0.0
                            except (ZeroDivisionError, TypeError, ValueError):
                                progress = 0.0
                            current_percent_for_log = int(progress // 5) * 5  # 5% ë‹¨ìœ„ (ë¡œê·¸ìš©)
                            current_percent_for_ui = int(progress * 2) / 2  # 0.5% ë‹¨ìœ„ (UI ì—…ë°ì´íŠ¸ìš©)
                            
                            # ì†ë„ ê³„ì‚°ì„ ìœ„í•œ ì‹œê°„ ì¶”ì 
                            current_time = time.time()
                            if not hasattr(req, '_local_speed_start_time'):
                                req._local_speed_start_time = current_time
                                req._local_speed_start_bytes = downloaded
                            
                            if downloaded - last_update_size >= 10485760 or current_percent_for_ui != getattr(req, '_last_ui_percent', 0):  # 10MBë§ˆë‹¤ ë˜ëŠ” 0.5% ë‹¨ìœ„ë¡œ ì—…ë°ì´íŠ¸
                                req.downloaded_size = downloaded
                                db.commit()
                                last_update_size = downloaded
                                
                                # 5% ë‹¨ìœ„ë¡œë§Œ ë¡œê·¸ ì¶œë ¥ (ì†ë„ í¬í•¨)
                                if current_percent_for_log != getattr(req, '_last_logged_percent', 0) and current_percent_for_log % 5 == 0 and current_percent_for_log > 0:
                                    req._last_logged_percent = current_percent_for_log
                                    # ì†ë„ ê³„ì‚° (ë¡œê·¸ìš©)
                                    time_elapsed = current_time - req._local_speed_start_time
                                    if time_elapsed > 0:
                                        bytes_diff = downloaded - req._local_speed_start_bytes
                                        download_speed = bytes_diff / time_elapsed
                                        speed_mb = download_speed / (1024 * 1024)
                                        print(f"[LOG] ë¡œì»¬ ì§„í–‰ë¥ : {current_percent_for_log}% ({downloaded}/{total_size}) - ì†ë„: {speed_mb:.2f}MB/s")
                                        req._local_speed_start_time = current_time
                                        req._local_speed_start_bytes = downloaded
                                
                                # 0.5% ë‹¨ìœ„ë¡œ WebSocket ì—…ë°ì´íŠ¸ (í™”ë©´ ì—…ë°ì´íŠ¸)
                                if current_percent_for_ui != getattr(req, '_last_ui_percent', 0):
                                    req._last_ui_percent = current_percent_for_ui
                                    
                                    # ì†ë„ëŠ” 2% ë‹¨ìœ„ë¡œë§Œ ì—…ë°ì´íŠ¸ (ë” ì•ˆì •ì )
                                    current_percent_for_speed = int(progress // 2) * 2
                                    download_speed = getattr(req, '_last_local_download_speed', 0)
                                    
                                    if current_percent_for_speed != getattr(req, '_last_local_speed_percent', 0):
                                        req._last_local_speed_percent = current_percent_for_speed
                                        # ì†ë„ ê³„ì‚° (ì²« 1ë¶„ì€ 2ì´ˆ, ì´í›„ 4ì´ˆ ê°„ê²©)
                                        speed_time_elapsed = current_time - getattr(req, '_local_ui_speed_time', current_time - 4)
                                        download_start_time = getattr(req, '_local_download_start_time', current_time)
                                        is_initial_phase = (current_time - download_start_time) < 60  # ì²« 1ë¶„
                                        
                                        min_interval = 2.0 if is_initial_phase else 4.0
                                        if speed_time_elapsed >= min_interval or not hasattr(req, '_local_ui_speed_time'):
                                            speed_bytes_diff = downloaded - getattr(req, '_local_ui_speed_bytes', downloaded)
                                            if speed_time_elapsed > 0 and speed_bytes_diff > 0:
                                                download_speed = speed_bytes_diff / speed_time_elapsed
                                            elif not hasattr(req, '_local_ui_speed_time'):
                                                # ì²« ì¸¡ì •ì‹œì—ëŠ” ê¸°ë³¸ê°’
                                                download_speed = 0
                                            req._local_ui_speed_time = current_time
                                            req._local_ui_speed_bytes = downloaded
                                            req._last_local_download_speed = download_speed
                                            if not hasattr(req, '_local_download_start_time'):
                                                req._local_download_start_time = current_time
                                    
                                    send_websocket_message("progress_update", {
                                        "id": req.id,
                                        "downloaded_size": downloaded,
                                        "total_size": total_size,
                                        "progress": round(max(0.0, min(100.0, progress or 0.0)), 1),
                                        "download_speed": round(download_speed, 0),
                                        "status": "downloading"
                                    })
                    
                    req.downloaded_size = downloaded
                    db.commit()
                
            except Exception as file_error:
                raise Exception(f"íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨: {file_error}")
                
        print(f"[LOG] ë¡œì»¬ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {downloaded} bytes")
        
        # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í›„ íŒŒì¼ ê²€ì¦
        if downloaded == 0:
            print(f"[LOG] ê²½ê³ : ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°ê°€ 0 bytes")
            raise Exception("ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - ë°›ì€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        # Content-Typeìœ¼ë¡œ ì˜ëª»ëœ íŒŒì¼ ê°ì§€ (ìš©ëŸ‰ì€ ì²´í¬í•˜ì§€ ì•ŠìŒ)
        content_type = response.headers.get('Content-Type', '').lower()
        if any(wrong_type in content_type for wrong_type in ['text/html', 'text/css', 'text/javascript', 'application/json']):
            raise Exception(f"ì˜ëª»ëœ íŒŒì¼ íƒ€ì… ë‹¤ìš´ë¡œë“œ: {content_type} ({downloaded} bytes)")
        elif downloaded < 1024:  # 1KB ë¯¸ë§Œì€ í™•ì‹¤íˆ ë¬¸ì œ
            print(f"[LOG] ê²½ê³ : ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ë§¤ìš° ì‘ìŒ ({downloaded} bytes)")
            # ì‘ì€ íŒŒì¼ì˜ ë‚´ìš©ì„ í™•ì¸í•´ë´„
            try:
                with open(file_path, 'rb') as check_file:
                    content = check_file.read(500)
                    try:
                        text_content = content.decode('utf-8', errors='ignore').lower()
                        if any(indicator in text_content for indicator in ['<html', 'error', '404', '403']):
                            print(f"[LOG] ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ì—ëŸ¬ í˜ì´ì§€ì„: {text_content[:100]}...")
                            raise Exception(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - ì—ëŸ¬ í˜ì´ì§€ ë°›ìŒ ({downloaded} bytes)")
                    except:
                        pass
            except:
                pass
        
    except Exception as e:
        error_str = str(e)
        print(f"[LOG] ë¡œì»¬ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # DNS ì˜¤ë¥˜ ê°ì§€ ì‹œ ì¬íŒŒì‹± ì‹œë„
        if any(dns_error in error_str for dns_error in [
            "NameResolutionError", "Failed to resolve", "Name or service not known", 
            "No address associated with hostname", "nodename nor servname provided"
        ]):
            print(f"[LOG] DNS í•´ìƒë„ ì˜¤ë¥˜ ê°ì§€ - ë‹¤ìš´ë¡œë“œ ë§í¬ ì¬íŒŒì‹± ì‹œë„")
            print(f"[LOG] ë§Œë£Œëœ ë§í¬: {direct_link}")
            
            try:
                # ê¸°ì¡´ direct_link ì™„ì „ ì´ˆê¸°í™”
                req.direct_link = None
                db.commit()
                
                # ìš°ì„  ë¡œì»¬ ì—°ê²°ë¡œ ì¬íŒŒì‹± ì‹œë„
                print(f"[LOG] ë¡œì»¬ ì—°ê²°ìœ¼ë¡œ ê°•ì œ ì¬íŒŒì‹± ì‹œë„: {req.url}")
                from .parser_service import parse_direct_link_simple
                new_direct_link = parse_direct_link_simple(req.url, req.password, use_proxy=False)
                
                if new_direct_link and new_direct_link != direct_link:
                    print(f"[LOG] ë¡œì»¬ ì—°ê²° DNS ì˜¤ë¥˜ í›„ ì¬íŒŒì‹± ì„±ê³µ: {new_direct_link}")
                    req.direct_link = new_direct_link
                    db.commit()
                    return download_local(new_direct_link, file_path, initial_size, req, db)
                else:
                    print(f"[LOG] ë¡œì»¬ ì¬íŒŒì‹± ì‹¤íŒ¨ - í”„ë¡ì‹œ ìˆœí™˜ ì‹œë„")
                    
                    # ë¡œì»¬ ì¬íŒŒì‹± ì‹¤íŒ¨ ì‹œ í”„ë¡ì‹œë¡œ ì‹œë„
                    try:
                        new_direct_link, used_proxy = parse_with_proxy_cycling(req, db, force_reparse=True)
                        if new_direct_link and new_direct_link != direct_link:
                            print(f"[LOG] í”„ë¡ì‹œ ìˆœí™˜ìœ¼ë¡œ ì¬íŒŒì‹± ì„±ê³µ: {new_direct_link}")
                            req.direct_link = new_direct_link
                            db.commit()
                            
                            if used_proxy:
                                return download_with_proxy(new_direct_link, file_path, used_proxy, initial_size, req, db)
                            else:
                                return download_local(new_direct_link, file_path, initial_size, req, db)
                        else:
                            print(f"[LOG] í”„ë¡ì‹œ ìˆœí™˜ ì¬íŒŒì‹±ë„ ì‹¤íŒ¨")
                    except Exception as proxy_error:
                        print(f"[LOG] í”„ë¡ì‹œ ìˆœí™˜ ì¬íŒŒì‹± ì¤‘ ì˜ˆì™¸: {proxy_error}")
                        
            except Exception as reparse_error:
                print(f"[LOG] DNS ì˜¤ë¥˜ í›„ ì¬íŒŒì‹± ì¤‘ ì˜ˆì™¸: {reparse_error}")
        
        # WebSocketìœ¼ë¡œ ë¡œì»¬ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ìƒíƒœ ì „ì†¡
        send_websocket_message("status_update", {
            "id": req.id,
            "url": req.url,
            "file_name": req.file_name,
            "status": "failed",
            "error": str(e),
            "downloaded_size": req.downloaded_size or 0,
            "total_size": req.total_size or 0,
            "save_path": req.save_path,
            "requested_at": req.requested_at.isoformat() if req.requested_at else None,
            "finished_at": None,
            "password": req.password,
            "direct_link": req.direct_link,
            "use_proxy": req.use_proxy
        })
        
        raise e


def download_from_stream(proxy_addr, file_path, initial_size, req, db, use_proxy):
    """ì§ì ‘ ë‹¤ìš´ë¡œë“œ ìŠ¤íŠ¸ë¦¼ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    print(f"[LOG] ì§ì ‘ ìŠ¤íŠ¸ë¦¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘ (í”„ë¡ì‹œ: {proxy_addr})")
    
    # ìŠ¤íŠ¸ë¦¼ ë‹¤ìš´ë¡œë“œëŠ” parser_serviceì—ì„œ ì´ë¯¸ ì‹œì‘ë˜ì—ˆìœ¼ë¯€ë¡œ
    # ì—¬ê¸°ì„œëŠ” ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„
    try:
        # ìƒˆë¡œìš´ ìš”ì²­ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ì¬ì‹œì‘
        from .parser_service import get_or_parse_direct_link
        
        if use_proxy and proxy_addr:
            # í”„ë¡ì‹œ ì‚¬ìš©í•˜ì—¬ ë‹¤ìš´ë¡œë“œ ì¬ì‹œì‘
            print(f"[LOG] í”„ë¡ì‹œ {proxy_addr}ë¡œ ìŠ¤íŠ¸ë¦¼ ë‹¤ìš´ë¡œë“œ ì¬ì‹œì‘")
            download_with_proxy("STREAM_RETRY", file_path, proxy_addr, initial_size, req, db)
        else:
            # ë¡œì»¬ ì—°ê²°ë¡œ ë‹¤ìš´ë¡œë“œ ì¬ì‹œì‘
            print(f"[LOG] ë¡œì»¬ ì—°ê²°ë¡œ ìŠ¤íŠ¸ë¦¼ ë‹¤ìš´ë¡œë“œ ì¬ì‹œì‘")
            download_local("STREAM_RETRY", file_path, initial_size, req, db)
            
    except Exception as e:
        print(f"[LOG] ìŠ¤íŠ¸ë¦¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise e


def cleanup_download_file(file_path):
    """ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í›„ íŒŒì¼ ì •ë¦¬ - .part í™•ì¥ì ì œê±°"""
    try:
        file_path_str = str(file_path)
        
        if file_path_str.endswith('.part'):
            final_path = file_path_str[:-5]  # .part ì œê±°
            print(f"[LOG] .part íŒŒì¼ì„ ìµœì¢… íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½: {file_path} -> {final_path}")
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                print(f"[LOG] ìµœì¢… íŒŒì¼ í¬ê¸°: {file_size} bytes")
                
                # íŒŒì¼ì´ ë§¤ìš° ì‘ê±°ë‚˜ ë¹ˆ ê²½ìš° ë‚´ìš© ê²€ì¦
                if file_size < 1024:
                    print(f"[LOG] ì‘ì€ íŒŒì¼ ê²€ì¦ ì¤‘... ({file_size} bytes)")
                    try:
                        with open(file_path, 'rb') as f:
                            content = f.read(500)
                            try:
                                text_content = content.decode('utf-8', errors='ignore').lower()
                                error_indicators = ['<html', '<body', 'error', '404', '403', 'not found']
                                if any(indicator in text_content for indicator in error_indicators):
                                    print(f"[LOG] ì—ëŸ¬ íŒŒì¼ ê°ì§€ - ì‚­ì œí•¨: {text_content[:100]}...")
                                    os.remove(file_path)
                                    raise Exception(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - ì—ëŸ¬ í˜ì´ì§€ ë°›ìŒ ({file_size} bytes)")
                            except UnicodeDecodeError:
                                # ë°”ì´ë„ˆë¦¬ íŒŒì¼ì¸ ê²½ìš° í†µê³¼
                                pass
                    except Exception as e:
                        if "ì—ëŸ¬ í˜ì´ì§€" in str(e):
                            raise e  # ì—ëŸ¬ í˜ì´ì§€ì¸ ê²½ìš° ì˜ˆì™¸ ì „íŒŒ
                        pass  # ê¸°íƒ€ íŒŒì¼ ì½ê¸° ì—ëŸ¬ëŠ” ë¬´ì‹œ
                
                # .part í™•ì¥ì ì œê±°í•˜ì—¬ ìµœì¢… íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½
                if os.path.exists(final_path):
                    # ì¤‘ë³µ íŒŒì¼ ì²˜ë¦¬
                    counter = 1
                    base_name, ext = os.path.splitext(final_path)
                    while os.path.exists(f"{base_name}_{counter}{ext}"):
                        counter += 1
                    final_path = f"{base_name}_{counter}{ext}"
                    print(f"[LOG] ì¤‘ë³µ íŒŒì¼ ë°©ì§€: {final_path}")
                
                os.rename(file_path, final_path)
                print(f"[LOG] íŒŒì¼ëª… ì •ë¦¬ ì™„ë£Œ: {final_path}")
                return final_path
            else:
                print(f"[LOG] íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
                return None
        else:
            print(f"[LOG] .part í™•ì¥ìê°€ ì•„ë‹Œ íŒŒì¼ì€ ê·¸ëŒ€ë¡œ ìœ ì§€: {file_path}")
            return file_path
    except Exception as e:
        print(f"[LOG] íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        raise e


def download_general_file(request_id, language="ko", use_proxy=False):
    """ì¼ë°˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (non-1fichier) - URLì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ"""
    from .db import SessionLocal
    from .models import DownloadRequest, StatusEnum
    from urllib.parse import urlparse, unquote
    import requests
    import re
    
    db = SessionLocal()
    req = None  # ë³€ìˆ˜ ì´ˆê¸°í™”
    
    try:
        # ë‹¤ìš´ë¡œë“œ ìš”ì²­ ì¡°íšŒ
        req = db.query(DownloadRequest).filter(DownloadRequest.id == request_id).first()
        if not req:
            print(f"[LOG] ì¼ë°˜ ë‹¤ìš´ë¡œë“œ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {request_id}")
            return
        
        print(f"[LOG] ì¼ë°˜ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {req.url}")
        
        # ë¨¼ì € HEAD ìš”ì²­ìœ¼ë¡œ íŒŒì¼ ì •ë³´ í™•ì¸ (íŒŒì¼ëª… ìƒì„± ì „)
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            head_response = requests.head(req.url, headers=headers, timeout=30, allow_redirects=True)
            if head_response.status_code == 200:
                # Content-Type ì²´í¬ - ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼ì¸ì§€ ë¨¼ì € í™•ì¸
                content_type = head_response.headers.get('Content-Type', '').lower()
                
                # HTML í˜ì´ì§€ë‚˜ ì¼ë°˜ ì›¹í˜ì´ì§€ëŠ” ë‹¤ìš´ë¡œë“œí•˜ì§€ ì•ŠìŒ (íŒŒì¼ëª… ìƒì„± ì „ì— ì°¨ë‹¨)
                if any(web_type in content_type for web_type in ['text/html', 'text/xml', 'application/json', 'text/plain']):
                    print(f"[LOG] ì›¹í˜ì´ì§€ Content-Type ê°ì§€: {content_type} - ë‹¤ìš´ë¡œë“œ ë¶ˆê°€")
                    req.status = StatusEnum.failed
                    req.error_message = f"ì›¹í˜ì´ì§€ëŠ” ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Content-Type: {content_type})"
                    db.commit()
                    return
                
                print(f"[LOG] ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ Content-Type: {content_type}")
                
            else:
                print(f"[LOG] HEAD ìš”ì²­ ì‹¤íŒ¨: {head_response.status_code}")
                req.status = StatusEnum.failed
                req.error_message = f"ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {head_response.status_code}"
                db.commit()
                return
                
        except Exception as head_e:
            print(f"[LOG] HEAD ìš”ì²­ ì¤‘ ì˜¤ë¥˜: {head_e}")
            req.status = StatusEnum.failed
            req.error_message = f"HEAD ìš”ì²­ ì‹¤íŒ¨: {str(head_e)}"
            db.commit()
            return
        
        # Content-Type í™•ì¸ í›„ íŒŒì¼ëª… ìƒì„±
        # URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
        parsed_url = urlparse(req.url)
        if parsed_url.path and '/' in parsed_url.path:
            url_filename = unquote(parsed_url.path.split('/')[-1])
            if url_filename and len(url_filename) > 3 and '.' in url_filename:
                print(f"[LOG] URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ: '{url_filename}'")
                req.file_name = url_filename
                db.commit()
        
        # Content-Dispositionì—ì„œ íŒŒì¼ëª… ì¬ì¶”ì¶œ ì‹œë„
        content_disposition = head_response.headers.get('Content-Disposition')
        if content_disposition and 'filename=' in content_disposition:
            filename_match = re.search(r'filename[*]?=(?:UTF-8\'\')?["\']?([^"\';]+)["\']?', content_disposition, re.IGNORECASE)
            if filename_match:
                extracted_filename = unquote(filename_match.group(1))
                req.file_name = extracted_filename
                print(f"[LOG] Content-Dispositionì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ: '{extracted_filename}'")
        
        # íŒŒì¼ëª…ì´ ì—†ìœ¼ë©´ ì„ì‹œëª… ì„¤ì •
        if not req.file_name or req.file_name.strip() == '':
            req.file_name = f"general_{request_id}.tmp"
            print(f"[LOG] íŒŒì¼ëª…ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ì–´ ì„ì‹œëª… ì‚¬ìš©: {req.file_name}")
            
        # Content-Lengthì—ì„œ íŒŒì¼ í¬ê¸° ì¶”ì¶œ
        content_length = head_response.headers.get('Content-Length')
        if content_length:
            bytes_size = int(content_length)
            
            # 1fichierì²˜ëŸ¼ í¬ë§·íŒ…ëœ í¬ê¸°ë¥¼ ë¬¸ìì—´ë¡œ ì €ì¥
            formatted_size = format_file_size(bytes_size)
            req.file_size = formatted_size
            print(f"[LOG] â˜… íŒŒì¼í¬ê¸° ìµœì´ˆ ì„¤ì •: '{formatted_size}' ({content_length} bytes)")
        
        # ìƒíƒœë¥¼ ë‹¤ìš´ë¡œë“œ ì¤‘ìœ¼ë¡œ ë³€ê²½
        req.status = StatusEnum.downloading
        db.commit()
        
        # WebSocketìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì•Œë¦¼
        send_websocket_message("status_update", {
            "id": req.id,
            "url": req.url,
            "file_name": req.file_name,
            "file_size": req.file_size,
            "status": "downloading",
            "error": None,
            "progress": 0,
            "downloaded_size": 0,
            "total_size": 0, # ì‹¤ì œ í¬ê¸°ëŠ” ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì‹œ ì—…ë°ì´íŠ¸ë¨
            "save_path": None,
            "requested_at": req.requested_at.isoformat() if req.requested_at else None,
            "finished_at": None,
            "password": req.password,
            "direct_link": None,
            "use_proxy": req.use_proxy
        })
        
        # ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì„¤ì •
        download_path = get_download_path()
        
        # Windowsì—ì„œ íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        safe_filename = re.sub(r'[<>:"/\\|?*]', '_', req.file_name.strip())
        safe_filename = safe_filename.strip('. ')
        
        if not safe_filename:
            safe_filename = f"general_{request_id}.unknown"
            
        # ì¤‘ë³µ íŒŒì¼ëª… ë°©ì§€
        final_path = download_path / safe_filename
        counter = 1
        while final_path.exists():
            name, ext = os.path.splitext(safe_filename)
            safe_filename = f"{name}_{counter}{ext}"
            final_path = download_path / safe_filename
            counter += 1
            
        file_path = final_path
        part_file_path = download_path / (safe_filename + ".part")
        
        # DBì— ì €ì¥ ê²½ë¡œ ì—…ë°ì´íŠ¸
        req.save_path = str(file_path)
        db.commit()
        print(f"[LOG] ì €ì¥ ê²½ë¡œ ì„¤ì •: {file_path}")
        
        # ê¸°ì¡´ íŒŒì¼ í™•ì¸
        initial_size = 0
        if part_file_path.exists():
            file_path = part_file_path
            initial_size = part_file_path.stat().st_size
            print(f"[LOG] ì´ì–´ë°›ê¸°: {initial_size} bytes")
        elif file_path.exists():
            initial_size = file_path.stat().st_size
            print(f"[LOG] ê¸°ì¡´ íŒŒì¼ ë°œê²¬: {initial_size} bytes")
        else:
            file_path = part_file_path
            print(f"[LOG] ìƒˆ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        
        # ì‹¤ì œ ë‹¤ìš´ë¡œë“œëŠ” ê¸°ì¡´ ë‹¤ìš´ë¡œë“œ ë¡œì§ ì¬ì‚¬ìš©
        if use_proxy:
            print(f"[LOG] í”„ë¡ì‹œ ëª¨ë“œë¡œ ì¼ë°˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ")
            download_with_proxy_cycling(req.url, file_path, None, initial_size, req, db)
        else:
            print(f"[LOG] ë¡œì»¬ ëª¨ë“œë¡œ ì¼ë°˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ")
            download_local(req.url, file_path, initial_size, req, db)
            
        # 3ë‹¨ê³„: ì™„ë£Œ ì²˜ë¦¬
        db.refresh(req)
        if req.status == StatusEnum.stopped:
            print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì •ì§€ë¨ (ì™„ë£Œ ì²˜ë¦¬ ì „): ID {request_id}")
            return

        final_file_path = cleanup_download_file(file_path)

        req.status = StatusEnum.done
        import datetime
        req.finished_at = datetime.datetime.utcnow()
        if final_file_path:
            req.save_path = str(final_file_path)
        db.commit()

        # í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ (ì™„ë£Œ)
        unknown_file = get_translations(language).get("telegram_unknown_file", "ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼")
        
        file_size_str = req.file_size or "ì•Œ ìˆ˜ ì—†ìŒ"
        
        download_time_str = None
        if req.finished_at:
            if language == "ko":
                # í•œêµ­ì–´ì¼ ë•Œë§Œ KSTë¡œ ë³€í™˜
                kst_finished = req.finished_at + datetime.timedelta(hours=9)
                download_time_str = kst_finished.strftime("%Y-%m-%d %H:%M:%S")
            else:
                # ì˜ì–´ ë“± ë‹¤ë¥¸ ì–¸ì–´ëŠ” UTC ê·¸ëŒ€ë¡œ í‘œì‹œ
                download_time_str = req.finished_at.strftime("%Y-%m-%d %H:%M:%S UTC")
        
        # ì €ì¥ ê²½ë¡œ (ì–¸ì–´ë³„ ê¸°ë³¸ê°’)
        if language == "ko":
            save_path_str = req.save_path or "ê¸°ë³¸ê²½ë¡œ"
        else:
            save_path_str = req.save_path or "Default path"
        
        send_telegram_notification(
            req.file_name or unknown_file, 
            "done", 
            None, 
            language,
            file_size=file_size_str,
            download_time=download_time_str,
            save_path=save_path_str
        )
        
        # WebSocketìœ¼ë¡œ ì™„ë£Œ ìƒíƒœ ì „ì†¡
        send_websocket_message("status_update", {
            "id": req.id,
            "url": req.url,
            "file_name": req.file_name,
            "status": "done",
            "error": None,
            "downloaded_size": req.downloaded_size or 0,
            "total_size": req.total_size or 0,
            "progress": 100.0,
            "save_path": req.save_path,
            "requested_at": req.requested_at.isoformat() if req.requested_at else None,
            "finished_at": req.finished_at.isoformat() if req.finished_at else None,
            "password": req.password,
            "direct_link": req.direct_link,
            "use_proxy": req.use_proxy
        })
        
        print(f"[LOG] ì¼ë°˜ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {req.file_name}")
            
    except Exception as e:
        print(f"[LOG] ì¼ë°˜ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        if req:
            req.status = StatusEnum.failed
            req.error_message = str(e)
            db.commit()
        raise e
    finally:
        db.close()


