# -*- coding: utf-8 -*-
import sys
import os
import re

# UTF-8 ì¸ì½”ë”© ê°•ì œ ì„¤ì •
if sys.platform.startswith('win'):
    try:
        os.environ['PYTHONIOENCODING'] = 'utf-8'
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        pass

import requests
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from pydantic import BaseModel, HttpUrl
from core.models import DownloadRequest, Base, StatusEnum
from core.db import engine, get_db
from core.auth import get_current_user_optional, AUTHENTICATION_ENABLED
from typing import Dict, Any
from core.i18n import get_message
import json
import os
import re
import time

# í…Œì´ë¸” ìƒì„±ì€ main.pyì—ì„œ ì²˜ë¦¬

# ê¸°ì¡´ 'paused' ìƒíƒœë¥¼ 'stopped'ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
try:
    from sqlalchemy import text
    with engine.connect() as conn:
        result = conn.execute(text("UPDATE download_requests SET status = 'stopped' WHERE status = 'paused'"))
        conn.commit()
        if result.rowcount > 0:
            print(f"[LOG] {result.rowcount}ê°œì˜ 'paused' ë ˆì½”ë“œë¥¼ 'stopped'ë¡œ ë³€ê²½")
except Exception as e:
    print(f"[LOG] ìƒíƒœ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")

router = APIRouter()

class DownloadRequestCreate(BaseModel):
    url: HttpUrl
    password: str = ""
    use_proxy: bool = True
    file_name: str = None  # ìž¬ë‹¤ìš´ë¡œë“œì‹œ ê¸°ì¡´ íŒŒì¼ëª… ì „ë‹¬ìš©

@router.post("/parse-info/")
def parse_file_info_only(request: DownloadRequestCreate, db: Session = Depends(get_db)):
    """íŒŒì¼ ì •ë³´ë§Œ íŒŒì‹±í•˜ê³  ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •"""
    try:
        # ë¡œê·¸ íŒŒì¼ì—ë„ ê¸°ë¡
        try:
            import os
            log_path = "/tmp/debug.log" if os.path.exists("/tmp") else "debug.log"
            with open(log_path, "a", encoding="utf-8") as f:
                f.write(f"[{time.strftime('%H:%M:%S')}] PARSE INFO API CALLED: {request.url}\n")
                f.flush()
        except PermissionError:
            print(f"[{time.strftime('%H:%M:%S')}] PARSE INFO API CALLED: {request.url}")
        
        print("="*80)
        print("[LOG] *** PARSE FILE INFO API CALLED ***")
        print(f"[LOG] URL: {request.url}")
        print(f"[LOG] Use Proxy: {request.use_proxy}")
        print("="*80)
        
        # ê¸°ì¡´ ìš”ì²­ì´ ìžˆëŠ”ì§€ í™•ì¸ (íŒŒì¼ëª…ì´ ìžˆëŠ” ê²½ìš° ìž¬ì‚¬ìš©)
        existing_req = db.query(DownloadRequest).filter(
            DownloadRequest.url == str(request.url),
            DownloadRequest.file_name.isnot(None),
            DownloadRequest.file_name != ''
        ).order_by(DownloadRequest.requested_at.desc()).first()
        
        if existing_req and existing_req.file_name and existing_req.file_name.strip():
            print(f"[LOG] ê¸°ì¡´ íŒŒì‹± ê²°ê³¼ ìž¬ì‚¬ìš©: {existing_req.file_name}")
            return {
                "id": existing_req.id,
                "status": "parsed",
                "file_name": existing_req.file_name,
                "file_size": existing_req.file_size,
                "message": "File info reused from existing request"
            }
        
        # ìƒˆ ìš”ì²­ ìƒì„±
        db_req = DownloadRequest(
            url=str(request.url),
            status=StatusEnum.pending,  # ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •
            password=request.password,
            use_proxy=request.use_proxy,
            file_name=request.file_name  # ìž¬ë‹¤ìš´ë¡œë“œì‹œ ê¸°ì¡´ íŒŒì¼ëª… ì‚¬ìš©
        )
        db.add(db_req)
        db.commit()
        db.refresh(db_req)
        
        print(f"[LOG] íŒŒì¼ ì •ë³´ íŒŒì‹± ìš”ì²­ ìƒì„±: ID {db_req.id}")
        
        # URL íƒ€ìž… í™•ì¸ í›„ ì ì ˆí•œ íŒŒì‹± ë°©ë²• ì„ íƒ
        url_str = str(request.url)
        if re.match(r'https?://(?:[^\.]+\.)?1fichier\.com/', url_str.lower()):
            # 1fichier URL - ê¸°ì¡´ íŒŒì„œ ì‚¬ìš©
            from .parser_service import parse_direct_link_with_file_info
            
            try:
                print(f"[LOG] 1fichier íŒŒì¼ ì •ë³´ íŒŒì‹± ì‹œìž‘...")
                direct_link, file_info = parse_direct_link_with_file_info(
                    url_str,
                    request.password,
                    use_proxy=request.use_proxy
                )
            except Exception as parse_error:
                print(f"[ERROR] 1fichier íŒŒì¼ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨: {parse_error}")
                db_req.error = f"íŒŒì‹± ì‹¤íŒ¨: {str(parse_error)}"
                db_req.status = StatusEnum.failed
                db.commit()
                
                return {
                    "id": db_req.id,
                    "status": "failed",
                    "error": str(parse_error)
                }
        else:
            # ì¼ë°˜ URL - Content-Type ì²´í¬ í›„ íŒŒì¼ ì •ë³´ ì¶”ì¶œ
            try:
                print(f"[LOG] ì¼ë°˜ URL íŒŒì¼ ì •ë³´ ì²´í¬ ì‹œìž‘...")
                import requests
                from urllib.parse import urlparse, unquote
                
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
                
                head_response = requests.head(url_str, headers=headers, timeout=30, allow_redirects=True)
                if head_response.status_code == 200:
                    # Content-Type ì²´í¬ - ì›¹íŽ˜ì´ì§€ëŠ” ë°”ë¡œ ì°¨ë‹¨
                    content_type = head_response.headers.get('Content-Type', '').lower()
                    
                    if any(web_type in content_type for web_type in ['text/html', 'text/xml', 'application/json', 'text/plain']):
                        print(f"[LOG] ì›¹íŽ˜ì´ì§€ Content-Type ê°ì§€: {content_type} - íŒŒì‹± ë¶ˆê°€")
                        db_req.error = f"ì›¹íŽ˜ì´ì§€ëŠ” ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Content-Type: {content_type})"
                        db_req.status = StatusEnum.failed
                        db.commit()
                        
                        return {
                            "id": db_req.id,
                            "status": "failed",
                            "error": f"ì›¹íŽ˜ì´ì§€ëŠ” ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Content-Type: {content_type})"
                        }
                    
                    # íŒŒì¼ ì •ë³´ ì¶”ì¶œ
                    file_info = {}
                    direct_link = url_str  # ì¼ë°˜ URLì€ ê·¸ ìžì²´ê°€ ë‹¤ìš´ë¡œë“œ ë§í¬
                    
                    # URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
                    parsed_url = urlparse(url_str)
                    if parsed_url.path and '/' in parsed_url.path:
                        url_filename = unquote(parsed_url.path.split('/')[-1])
                        if url_filename and len(url_filename) > 3 and '.' in url_filename:
                            file_info['name'] = url_filename
                    
                    # Content-Dispositionì—ì„œ íŒŒì¼ëª… ìž¬ì¶”ì¶œ ì‹œë„
                    content_disposition = head_response.headers.get('Content-Disposition')
                    if content_disposition and 'filename=' in content_disposition:
                        filename_match = re.search(r'filename[*]?=(?:UTF-8\'\')?["\']?([^"\';]+)["\']?', content_disposition, re.IGNORECASE)
                        if filename_match:
                            file_info['name'] = unquote(filename_match.group(1))
                    
                    # Content-Lengthì—ì„œ íŒŒì¼ í¬ê¸° ì¶”ì¶œ
                    content_length = head_response.headers.get('Content-Length')
                    if content_length:
                        bytes_size = int(content_length)
                        
                        # í¬ë§·íŒ…ëœ í¬ê¸° ìƒì„±
                        if bytes_size >= 1024**3:
                            file_info['size'] = f"{bytes_size / (1024**3):.1f} GB"
                        elif bytes_size >= 1024**2:
                            file_info['size'] = f"{bytes_size / (1024**2):.1f} MB"
                        elif bytes_size >= 1024:
                            file_info['size'] = f"{bytes_size / 1024:.1f} KB"
                        else:
                            file_info['size'] = f"{bytes_size} bytes"
                    
                    print(f"[LOG] ì¼ë°˜ URL íŒŒì¼ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ: {file_info}")
                    
                else:
                    print(f"[LOG] HEAD ìš”ì²­ ì‹¤íŒ¨: {head_response.status_code}")
                    db_req.error = f"ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {head_response.status_code}"
                    db_req.status = StatusEnum.failed
                    db.commit()
                    
                    return {
                        "id": db_req.id,
                        "status": "failed",
                        "error": f"ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {head_response.status_code}"
                    }
                    
            except Exception as parse_error:
                print(f"[ERROR] ì¼ë°˜ URL íŒŒì¼ ì •ë³´ ì²´í¬ ì‹¤íŒ¨: {parse_error}")
                db_req.error = f"íŒŒì¼ ì •ë³´ ì²´í¬ ì‹¤íŒ¨: {str(parse_error)}"
                db_req.status = StatusEnum.failed
                db.commit()
                
                return {
                    "id": db_req.id,
                    "status": "failed",
                    "error": str(parse_error)
                }
        
        try:
            
            # íŒŒì¼ ì •ë³´ ì—…ë°ì´íŠ¸
            if file_info and file_info.get('name'):
                db_req.file_name = file_info['name']
                print(f"[LOG] íŒŒì¼ëª… ì¶”ì¶œ: {file_info['name']}")
            
            if file_info and file_info.get('size'):
                # í¬ê¸°ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜í•´ì„œ ì €ìž¥
                size_str = file_info['size']
                try:
                    import re
                    match = re.search(r'(\d+(?:\.\d+)?)\s*(KB|MB|GB|TB)', size_str, re.IGNORECASE)
                    if match:
                        value = float(match.group(1))
                        unit = match.group(2).upper()
                        
                        multipliers = {'KB': 1024, 'MB': 1024**2, 'GB': 1024**3, 'TB': 1024**4}
                        if unit in multipliers:
                            total_bytes = int(value * multipliers[unit])
                            db_req.total_size = total_bytes
                            print(f"[LOG] íŒŒì¼ í¬ê¸° ì¶”ì¶œ: {size_str} ({total_bytes} bytes)")
                except Exception as e:
                    print(f"[LOG] íŒŒì¼ í¬ê¸° íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            # direct_linkë„ ì €ìž¥ (ë‚˜ì¤‘ì— ë‹¤ìš´ë¡œë“œí•  ë•Œ ì‚¬ìš©)
            if direct_link:
                db_req.direct_link = direct_link
                print(f"[LOG] Direct link ì €ìž¥ë¨")
            
            db.commit()
            
            return {
                "id": db_req.id, 
                "status": "parsed",
                "file_name": db_req.file_name or "Unknown",
                "file_size": file_info.get('size') if file_info else None,
                "message": "File info parsed successfully, ready to download"
            }
            
        except Exception as parse_error:
            print(f"[ERROR] íŒŒì¼ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨: {parse_error}")
            db_req.error = f"íŒŒì‹± ì‹¤íŒ¨: {str(parse_error)}"
            db_req.status = StatusEnum.failed
            db.commit()
            
            return {
                "id": db_req.id,
                "status": "failed",
                "error": str(parse_error)
            }
            
    except Exception as e:
        print(f"[ERROR] Parse info API ì‹¤íŒ¨: {e}")
        return {
            "error": str(e),
            "status": "failed"
        }

@router.post("/download/")
def create_download_task(
    request: DownloadRequestCreate, 
    db: Session = Depends(get_db),
    user: Dict[str, Any] = Depends(get_current_user_optional)
):
    # ë¡œê·¸ íŒŒì¼ì—ë„ ê¸°ë¡ (ë„ì»¤ í™˜ê²½ì„ ìœ„í•´ /tmp ê²½ë¡œ ì‚¬ìš©)
    try:
        import os
        log_path = "/tmp/debug.log" if os.path.exists("/tmp") else "debug.log"
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(f"[{time.strftime('%H:%M:%S')}] API CALLED: {request.url}\n")
            f.flush()
    except PermissionError:
        # ê¶Œí•œ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì½˜ì†”ì—ë§Œ ì¶œë ¥
        print(f"[{time.strftime('%H:%M:%S')}] API CALLED: {request.url}")
    
    print("="*80)
    print("[LOG] *** CREATE DOWNLOAD TASK API CALLED ***")
    print(f"[LOG] URL: {request.url}")
    print(f"[LOG] Use Proxy: {request.use_proxy}")
    print("="*80)
    import sys
    sys.stdout.flush()  # ì¦‰ì‹œ ì¶œë ¥ ê°•ì œ
    
    # URL íƒ€ìž…ë³„ ì‚¬ì „ ê²€ì¦
    url_str = str(request.url)
    
    # 1fichierê°€ ì•„ë‹Œ ì¼ë°˜ URLì¸ ê²½ìš° Content-Type ë¯¸ë¦¬ ì²´í¬
    if not re.match(r'https?://(?:[^\.]+\.)?1fichier\.com/', url_str.lower()):
        print(f"[LOG] ì¼ë°˜ URL ê°ì§€, Content-Type ì‚¬ì „ ì²´í¬: {url_str}")
        
        try:
            import requests
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            head_response = requests.head(url_str, headers=headers, timeout=30, allow_redirects=True)
            if head_response.status_code == 200:
                content_type = head_response.headers.get('Content-Type', '').lower()
                
                # ì›¹íŽ˜ì´ì§€ëŠ” ë°”ë¡œ ê±°ë¶€
                if any(web_type in content_type for web_type in ['text/html', 'text/xml', 'application/json', 'text/plain']):
                    print(f"[LOG] ì›¹íŽ˜ì´ì§€ Content-Type ê°ì§€: {content_type} - ë‹¤ìš´ë¡œë“œ ìš”ì²­ ê±°ë¶€")
                    raise HTTPException(status_code=400, detail=f"ì›¹íŽ˜ì´ì§€ëŠ” ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Content-Type: {content_type})")
                
                print(f"[LOG] ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ Content-Type í™•ì¸: {content_type}")
            else:
                print(f"[LOG] HEAD ìš”ì²­ ì‹¤íŒ¨: {head_response.status_code}")
                raise HTTPException(status_code=400, detail=f"URLì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì‘ë‹µ ì½”ë“œ: {head_response.status_code})")
                
        except requests.exceptions.RequestException as e:
            print(f"[LOG] URL ì ‘ê·¼ ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=400, detail=f"URLì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    else:
        print(f"[LOG] 1fichier URL ê°ì§€: {url_str}")
    
    db_req = DownloadRequest(
        url=str(request.url),
        status=StatusEnum.pending,
        password=request.password,
        use_proxy=request.use_proxy
    )
    db.add(db_req)
    db.commit()
    db.refresh(db_req)
    
    # íŒŒì¼ ì •ë³´ ë¯¸ë¦¬ íŒŒì‹± (ë™ê¸°ì ìœ¼ë¡œ) - íŒŒì¼ëª…ì´ ì—†ì„ ë•Œë§Œ ì‹¤í–‰
    if not db_req.file_name or db_req.file_name.strip() == '':
        print(f"[LOG] íŒŒì¼ëª…ì´ ì—†ì–´ì„œ ì‚¬ì „ íŒŒì‹± ì‹œìž‘...")
        try:
            from .parser_service import parse_file_info_only
            file_info = parse_file_info_only(str(request.url), request.password, request.use_proxy)
            if file_info and file_info.get('name'):
                # í˜„ìž¬ DB ì„¸ì…˜ì—ì„œ ë°”ë¡œ ì—…ë°ì´íŠ¸
                db_req.file_name = file_info['name']
                db_req.file_size = file_info.get('size')
                db.commit()
                db.refresh(db_req)
                print(f"[LOG] ðŸ“ íŒŒì¼ ì •ë³´ ì‚¬ì „ íŒŒì‹± ì™„ë£Œ: {file_info['name']} ({file_info.get('size', 'ì•Œ ìˆ˜ ì—†ìŒ')})")
                
                # SSEë¡œ UI ì—…ë°ì´íŠ¸
                from main import notify_status_update
                notify_status_update(db, db_req.id)
            else:
                print(f"[LOG] âš ï¸ íŒŒì¼ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨ - íŒŒì¼ëª…ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ")
        except Exception as e:
            print(f"[LOG] âŒ íŒŒì¼ ì •ë³´ ì‚¬ì „ íŒŒì‹± ì‹¤íŒ¨: {e}")
    else:
        print(f"[LOG] íŒŒì¼ëª…ì´ ì´ë¯¸ ì¡´ìž¬í•˜ì—¬ ì‚¬ì „ íŒŒì‹± ìŠ¤í‚µ: {db_req.file_name}")
    
    # ìƒˆë¡œìš´ ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ ì‚¬ìš©
    print(f"[LOG] ë°ì´í„°ë² ì´ìŠ¤ì— ì €ìž¥ëœ ìš”ì²­ ID: {db_req.id}")
    print(f"[LOG] ë‹¤ìš´ë¡œë“œ ìŠ¤ë ˆë“œ ì‹œìž‘ ì¤€ë¹„")
    
    from .download_core import download_1fichier_file_new
    from .shared import download_manager
    import threading
    
    # URL íƒ€ìž…ì— ë”°ë¼ ì ì ˆí•œ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ì„ íƒ
    if re.match(r'https?://(?:[^\.]+\.)?1fichier\.com/', db_req.url.lower()):
        # 1fichier ë‹¤ìš´ë¡œë“œ
        from .download_core import download_1fichier_file_new
        target_function = download_1fichier_file_new
        print(f"[LOG] 1fichier ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ì„ íƒ: {db_req.url}")
    else:
        # ì¼ë°˜ ë‹¤ìš´ë¡œë“œ
        from .download_core import download_general_file
        target_function = download_general_file
        print(f"[LOG] ì¼ë°˜ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ì„ íƒ: {db_req.url}")
    
    # ëª¨ë“  ë‹¤ìš´ë¡œë“œëŠ” ìŠ¤ë ˆë“œë¥¼ ì‹œìž‘í•¨ (ì œí•œ ì²´í¬ëŠ” ê° í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ)
    thread = threading.Thread(
        target=target_function,
        args=(db_req.id, "ko", request.use_proxy),
        daemon=True
    )
    print(f"[LOG] ìŠ¤ë ˆë“œ ì‹œìž‘ ì¤‘...")
    thread.start()
    print(f"[LOG] ìŠ¤ë ˆë“œ ì‹œìž‘ ì™„ë£Œ: {thread.is_alive()}")
    
    # ì œí•œ í™•ì¸ í›„ ì¦‰ì‹œ ì‘ë‹µ (ë¹„ë™ê¸° ì²˜ë¦¬)
    if not request.use_proxy:
        # 1fichier ë‹¤ìš´ë¡œë“œì¸ ê²½ìš° ì¦‰ì‹œ ì¿¨ë‹¤ìš´ í™•ì¸
        if "1fichier.com" in str(request.url).lower():
            cooldown_applied = download_manager.check_immediate_cooldown(db_req.id)
            if cooldown_applied:
                cooldown_remaining = download_manager.get_1fichier_cooldown_remaining()
                return {"id": db_req.id, "status": "cooldown", "message_key": "fichier_cooldown_active", "message_args": {"seconds": max(1, int(cooldown_remaining))}}
        
        if not download_manager.can_start_download(str(request.url)):
            print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì œí•œìœ¼ë¡œ ëŒ€ê¸° ìƒíƒœ ì˜ˆìƒ: {db_req.id}")
            # ì–´ë–¤ ì œí•œì¸ì§€ í™•ì¸í•˜ì—¬ ì ì ˆí•œ ë©”ì‹œì§€ ë°˜í™˜
            if len(download_manager.all_downloads) >= download_manager.MAX_TOTAL_DOWNLOADS:
                return {"id": db_req.id, "status": "waiting", "message_key": "total_download_limit_reached", "message_args": {"limit": download_manager.MAX_TOTAL_DOWNLOADS}}
            elif len(download_manager.local_downloads) >= download_manager.MAX_LOCAL_DOWNLOADS:
                return {"id": db_req.id, "status": "waiting", "message_key": "local_download_limit_reached", "message_args": {"limit": download_manager.MAX_LOCAL_DOWNLOADS}}
            else:
                cooldown_remaining = download_manager.get_1fichier_cooldown_remaining()
                if cooldown_remaining > 0:
                    return {"id": db_req.id, "status": "waiting", "message_key": "fichier_cooldown_active", "message_args": {"seconds": max(1, int(cooldown_remaining))}}
                # ì¿¨ë‹¤ìš´ì´ ëë‚œ ê²½ìš°ëŠ” ì •ìƒ ì§„í–‰
    
    return {"id": db_req.id, "status": db_req.status}

@router.get("/history/")
def get_download_history(db: Session = Depends(get_db), limit: int = 100):
    try:
        # ìµœê·¼ 100ê°œë§Œ ê°€ì ¸ì˜¤ê¸° (íŽ˜ì´ì§€ë„¤ì´ì…˜ ìµœì í™”)
        history = db.query(DownloadRequest).order_by(DownloadRequest.requested_at.desc()).limit(limit).all()
        print(f"[LOG] History API: Found {len(history)} records (limit: {limit})")
        result = [item.as_dict() for item in history]
        print(f"[LOG] History API: Returning {len(result)} items")
        return result
    except Exception as e:
        print(f"[ERROR] History API failed: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to fetch history: {str(e)}")

@router.get("/history/{download_id}")
def get_download_detail(download_id: int, db: Session = Depends(get_db)):
    item = db.query(DownloadRequest).filter(DownloadRequest.id == download_id).first()
    if item is None:
        raise HTTPException(status_code=404, detail="Download not found")
    return item.as_dict()

@router.post("/start-download/{download_id}")
def start_actual_download(download_id: int, db: Session = Depends(get_db)):
    """íŒŒì‹±ëœ íŒŒì¼ì˜ ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ì‹œìž‘"""
    item = db.query(DownloadRequest).filter(DownloadRequest.id == download_id).first()
    if item is None:
        raise HTTPException(status_code=404, detail="Download not found")
    
    # pending ìƒíƒœì—ì„œë§Œ ë‹¤ìš´ë¡œë“œ ì‹œìž‘ ê°€ëŠ¥
    if getattr(item, 'status', None) != StatusEnum.pending:
        raise HTTPException(status_code=400, detail=f"Download is not in pending state. Current status: {item.status}")
    
    print(f"[LOG] ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ì‹œìž‘: ID {download_id}, íŒŒì¼ëª…: {item.file_name}")
    
    # ë‹¤ìš´ë¡œë“œ ì œí•œ ì²´í¬
    from .shared import download_manager
    original_use_proxy = getattr(item, 'use_proxy', False)
    
    # ë‹¤ìš´ë¡œë“œ ì œí•œ ì²´í¬ (í”„ë¡ì‹œ ì‚¬ìš© ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ëª¨ë“  ë‹¤ìš´ë¡œë“œì—ì„œ ì²´í¬)
    if not download_manager.can_start_download(item.url):
        # ëŒ€ê¸° ìƒíƒœ ìœ ì§€ (ë‹¤ìš´ë¡œë“œ ì œí•œì´ë‚˜ ì¿¨ë‹¤ìš´ ë•Œë¬¸ì— ì‹œìž‘í•  ìˆ˜ ì—†ìŒ)
        setattr(item, "status", StatusEnum.pending)
        db.commit()
        return {"id": item.id, "status": "waiting", "message": "Download limit reached, staying in queue"}
    
    # ë‹¤ìš´ë¡œë“œ ì‹œìž‘
    setattr(item, "status", StatusEnum.downloading)
    db.commit()
    
    # URL íƒ€ìž…ì— ë”°ë¼ ì ì ˆí•œ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ì„ íƒ
    if "1fichier.com" in item.url.lower():
        from .download_core import download_1fichier_file_new
        target_function = download_1fichier_file_new
    else:
        from .download_core import download_general_file
        target_function = download_general_file
    
    import threading
    
    thread = threading.Thread(
        target=target_function,
        args=(download_id, "ko", original_use_proxy),
        daemon=True
    )
    thread.start()
    
    return {"id": item.id, "status": item.status, "message": "Download started"}

@router.post("/resume/{download_id}")
def resume_download(download_id: int, use_proxy: bool = False, db: Session = Depends(get_db)):
    item = db.query(DownloadRequest).filter(DownloadRequest.id == download_id).first()
    if item is None:
        raise HTTPException(status_code=404, detail="Download not found")
    
    # stopped ë˜ëŠ” pending ìƒíƒœì¸ ê²½ìš° ìž¬ê°œ/ì‹œìž‘
    if getattr(item, 'status', None) in [StatusEnum.stopped, StatusEnum.pending]:
        print(f"[LOG] ë‹¤ìš´ë¡œë“œ ìž¬ê°œ ìš”ì²­: ID {download_id}, í˜„ìž¬ ìƒíƒœ: {item.status}")
        
        # ìƒˆë¡œìš´ í”„ë¡ì‹œ ì„¤ì • ì ìš© (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ìš°ì„ )
        print(f"[LOG] í”„ë¡ì‹œ ì„¤ì • - ìš”ì²­ëœ use_proxy: {use_proxy}, DB ì €ìž¥ëœ use_proxy: {getattr(item, 'use_proxy', None)}")
        
        # ìƒˆ ì„¤ì •ì„ DBì— ì €ìž¥
        setattr(item, 'use_proxy', use_proxy)
        db.commit()
        
        print(f"[LOG] ìƒˆ í”„ë¡ì‹œ ì„¤ì •ìœ¼ë¡œ ìž¬ê°œ: use_proxy={use_proxy}, ID {download_id}")
        
        # ë¡œì»¬ ë‹¤ìš´ë¡œë“œì¸ ê²½ìš° ë‹¤ìš´ë¡œë“œ ì œí•œ ì²´í¬
        if not use_proxy:
            from .shared import download_manager
            if not download_manager.can_start_download(item.url):
                # ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •
                setattr(item, "status", StatusEnum.pending)
                db.commit()
                
                # SSEë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì•Œë¦¼ (ëŒ€ê¸° ìƒíƒœ)
                try:
                    from main import notify_status_update
                    notify_status_update(db, download_id)
                    print(f"[LOG] â˜… ëŒ€ê¸° ìƒíƒœ SSE ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ: ID={download_id}")
                except Exception as e:
                    print(f"[LOG] SSE ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
                
                # ì–´ë–¤ ì œí•œì¸ì§€ í™•ì¸í•˜ê³  DB ìƒíƒœë¥¼ pendingìœ¼ë¡œ ì„¤ì •
                if len(download_manager.all_downloads) >= download_manager.MAX_TOTAL_DOWNLOADS:
                    print(f"[LOG] ìž¬ê°œ - ì „ì²´ ë‹¤ìš´ë¡œë“œ ì œí•œ ë„ë‹¬ ({download_manager.MAX_TOTAL_DOWNLOADS}ê°œ). ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •: {download_id}")
                    setattr(item, "status", StatusEnum.pending)
                    db.commit()
                    return {"id": item.id, "status": "waiting", "message_key": "total_download_limit_reached", "message_args": {"limit": download_manager.MAX_TOTAL_DOWNLOADS}}
                elif len(download_manager.local_downloads) >= download_manager.MAX_LOCAL_DOWNLOADS:
                    print(f"[LOG] ìž¬ê°œ - 1fichier ë¡œì»¬ ë‹¤ìš´ë¡œë“œ ì œí•œ ë„ë‹¬ ({download_manager.MAX_LOCAL_DOWNLOADS}ê°œ). ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •: {download_id}")
                    setattr(item, "status", StatusEnum.pending)
                    db.commit()
                    return {"id": item.id, "status": "waiting", "message_key": "local_download_limit_reached", "message_args": {"limit": download_manager.MAX_LOCAL_DOWNLOADS}}
                else:
                    # ì¿¨ë‹¤ìš´ ì œí•œì¸ ê²½ìš°
                    cooldown_remaining = download_manager.get_1fichier_cooldown_remaining()
                    if cooldown_remaining > 0:
                        print(f"[LOG] ìž¬ê°œ - 1fichier ì¿¨ë‹¤ìš´ ì¤‘ ({cooldown_remaining:.1f}ì´ˆ ë‚¨ìŒ). ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •: {download_id}")
                        setattr(item, "status", StatusEnum.pending)
                        db.commit()
                        return {"id": item.id, "status": "waiting", "message_key": "fichier_cooldown_active", "message_args": {"seconds": max(1, int(cooldown_remaining))}}
                    # ì¿¨ë‹¤ìš´ì´ ëë‚œ ê²½ìš°ëŠ” ì •ìƒ ì§„í–‰
        
        # ì œí•œì— ê±¸ë¦¬ì§€ ì•Šì€ ê²½ìš° ì¦‰ì‹œ ì‹œìž‘
        setattr(item, "status", StatusEnum.downloading)
        db.commit()
        
        # WebSocketìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì•Œë¦¼ (ë‹¤ìš´ë¡œë“œ ì‹œìž‘)
        try:
            from main import notify_status_update
            notify_status_update(db, download_id)
            print(f"[LOG] â˜… ìž¬ê°œ SSE ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ: ID={download_id}")
        except Exception as e:
            print(f"[LOG] SSE ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
        
        # URL íƒ€ìž…ì— ë”°ë¼ ì ì ˆí•œ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ì„ íƒ (ìž¬ì‹œìž‘)
        if "1fichier.com" in item.url.lower():
            from .download_core import download_1fichier_file_new
            target_function = download_1fichier_file_new
        else:
            from .download_core import download_general_file
            target_function = download_general_file
        
        import threading
        
        thread = threading.Thread(
            target=target_function,
            args=(download_id, "ko", use_proxy),
            daemon=True
        )
        thread.start()
        
        # ì‹¤ì œë¡œ ì´ì–´ë°›ê¸°ì¸ì§€ ìƒˆ ë‹¤ìš´ë¡œë“œì¸ì§€ êµ¬ë¶„í•˜ì—¬ ë©”ì‹œì§€ ë°˜í™˜
        downloaded_size = getattr(item, 'downloaded_size', 0) or 0
        
        # ì‹¤ì œ íŒŒì¼ ì¡´ìž¬ ì—¬ë¶€ë„ ì²´í¬
        is_actual_resume = False
        if item.file_name:
            from .config import get_download_path
            from pathlib import Path
            import os
            
            download_dir = Path(get_download_path())
            part_file = download_dir / f"{item.file_name}.part"
            complete_file = download_dir / item.file_name
            
            if part_file.exists() and part_file.stat().st_size > 0:
                is_actual_resume = True
                print(f"[LOG] Resume API - .part íŒŒì¼ ì¡´ìž¬: {part_file.stat().st_size} bytes")
            elif complete_file.exists():
                is_actual_resume = True
                print(f"[LOG] Resume API - ì™„ë£Œ íŒŒì¼ ì¡´ìž¬: {complete_file.stat().st_size} bytes")
        
        print(f"[LOG] Resume API - downloaded_size: {downloaded_size}, file_exists: {is_actual_resume}")
        
        if downloaded_size > 0 or is_actual_resume:
            return {"id": item.id, "status": item.status, "message": "Download resumed"}
        else:
            return {"id": item.id, "status": item.status, "message": "Download started"}
    else:
        raise HTTPException(status_code=400, detail="Download is not in a stopped or pending state")

@router.delete("/delete/{download_id}")
def delete_download(download_id: int, db: Session = Depends(get_db)):
    item = db.query(DownloadRequest).filter(DownloadRequest.id == download_id).first()
    if item is None:
        raise HTTPException(status_code=404, detail="Download not found")
    
    print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì‚­ì œ ìš”ì²­: ID {download_id}, í˜„ìž¬ ìƒíƒœ: {item.status}")
    
    # ë‹¤ìš´ë¡œë“œ ì¤‘ì¸ ê²½ìš° ë¨¼ì € ì •ì§€
    if item.status in [StatusEnum.downloading, StatusEnum.proxying, StatusEnum.parsing, StatusEnum.pending]:
        print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì¤‘ì´ë¯€ë¡œ ë¨¼ì € ì •ì§€: ID {download_id}")
        setattr(item, "status", StatusEnum.stopped)
        db.commit()
        
        # ìž ì‹œ ëŒ€ê¸° (ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ê°€ ì •ì§€ë¥¼ ê°ì§€í•  ì‹œê°„)
        import time
        time.sleep(1)
    
    # ì‚­ì œ ì „ì— ë‹¤ìš´ë¡œë“œ ë§¤ë‹ˆì €ì—ì„œ í•´ì œ (ëŒ€ê¸° ì¤‘ì¸ ë‹¤ìš´ë¡œë“œ ì‹œìž‘ì„ ìœ„í•´)
    from .shared import download_manager
    download_manager.unregister_download(download_id)
    
    # DBì—ì„œ ì‚­ì œ
    db.delete(item)
    db.commit()
    
    print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì‚­ì œ ì™„ë£Œ: ID {download_id}")
    
    return {"message": "Download deleted successfully"}

@router.post("/pause/{download_id}")
def pause_download(download_id: int, db: Session = Depends(get_db)):
    item = db.query(DownloadRequest).filter(DownloadRequest.id == download_id).first()
    if item is None:
        raise HTTPException(status_code=404, detail="Download not found")
    
    print(f"[LOG] ë‹¤ìš´ë¡œë“œ ì •ì§€ ìš”ì²­: ID {download_id}, í˜„ìž¬ ìƒíƒœ: {item.status}")
    
    # pending, downloading, proxying, parsing ìƒíƒœë§Œ ì •ì§€ ê°€ëŠ¥
    if item.status not in [StatusEnum.pending, StatusEnum.downloading, StatusEnum.proxying, StatusEnum.parsing]:
        raise HTTPException(status_code=400, detail=f"í˜„ìž¬ ìƒíƒœ({item.status})ì—ì„œëŠ” ì •ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # ìƒíƒœë¥¼ stoppedë¡œ ë³€ê²½
    setattr(item, "status", StatusEnum.stopped)
    db.commit()
    
    print(f"[LOG] ë‹¤ìš´ë¡œë“œ ìƒíƒœë¥¼ stoppedë¡œ ë³€ê²½ ì™„ë£Œ: ID {download_id}")
    
    # ì¦‰ì‹œ ì •ì§€ í”Œëž˜ê·¸ ì„¤ì • (ì•ˆì „í•œ ì¦‰ì‹œ ì •ì§€)
    from .shared import download_manager
    download_manager.stop_download_immediately(download_id)
    
    # ì •ì§€ í›„ ë‹¤ìš´ë¡œë“œ ë§¤ë‹ˆì €ì—ì„œ í•´ì œ (ì •ì§€ ì‹œì—ëŠ” ìžë™ ì‹œìž‘ ì•ˆ í•¨)
    download_manager.unregister_download(download_id, auto_start_next=False)
    
    # SSEë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì•Œë¦¼ (ê°•ì œ ìƒˆë¡œê³ ì¹¨)
    try:
        from main import notify_status_update
        notify_status_update(db, download_id)
        print(f"[LOG] â˜… ì •ì§€ SSE ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ: ID={download_id}")
        
    except Exception as e:
        print(f"[LOG] SSE ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
    
    return {"id": item.id, "status": item.status, "message": "Download stopped successfully", "success": True}

@router.post("/retry/{download_id}")
def retry_download(download_id: int, db: Session = Depends(get_db)):
    item = db.query(DownloadRequest).filter(DownloadRequest.id == download_id).first()
    if item is None:
        raise HTTPException(status_code=404, detail="Download not found")
    
    print(f"[LOG] ë‹¤ìš´ë¡œë“œ ìž¬ì‹œë„ ìš”ì²­: ID {download_id}, í˜„ìž¬ ìƒíƒœ: {item.status}")
    
    # ì›ëž˜ í”„ë¡ì‹œ ì„¤ì • ì‚¬ìš© (ê¸°ë³¸ê°’ ì—†ì´)
    original_use_proxy = getattr(item, 'use_proxy', None)
    if original_use_proxy is None:
        # DBì— use_proxyê°€ ì—†ëŠ” ê²½ìš° (êµ¬ë²„ì „ í˜¸í™˜) - ê¸°ë³¸ê°’ False (ë¡œì»¬)
        original_use_proxy = False
        print(f"[LOG] retryì—ì„œ use_proxy ì„¤ì •ì´ ì—†ì–´ ê¸°ë³¸ê°’ False(ë¡œì»¬) ì‚¬ìš©: ID {download_id}")
    else:
        print(f"[LOG] retryì—ì„œ ì›ëž˜ í”„ë¡ì‹œ ì„¤ì • ì‚¬ìš©: use_proxy={original_use_proxy}, ID {download_id}")
    
    # ìž¬ì‹œë„ ì‹œì—ëŠ” í•­ìƒ ëŒ€ê¸° ìƒíƒœë¡œ ì¶”ê°€ (íì—ì„œ ìˆœì„œ ëŒ€ê¸°)
    setattr(item, "status", StatusEnum.pending)
    setattr(item, "error", None)
    setattr(item, "direct_link", None)  # ìž¬ì‹œë„ ì‹œ ìƒˆë¡œìš´ ë§í¬ íŒŒì‹± ê°•ì œ
    db.commit()
    
    print(f"[LOG] ìž¬ì‹œë„ ìš”ì²­ì´ ëŒ€ê¸° íì— ì¶”ê°€ë¨: ID {download_id}")
    
    # í”„ë¡ì‹œ ë‹¤ìš´ë¡œë“œì¸ ê²½ìš° ì¦‰ì‹œ ì‹œìž‘ ê°€ëŠ¥
    if original_use_proxy:
        from .download_core import download_1fichier_file_new
        import threading
        
        setattr(item, "status", StatusEnum.downloading)
        db.commit()
        
        # URL íƒ€ìž…ì— ë”°ë¼ ì ì ˆí•œ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ì„ íƒ (ìž¬ì‹œë„)
        if "1fichier.com" in item.url.lower():
            from .download_core import download_1fichier_file_new
            target_function = download_1fichier_file_new
        else:
            from .download_core import download_general_file
            target_function = download_general_file
        
        thread = threading.Thread(
            target=target_function,
            args=(download_id, "ko", original_use_proxy),
            daemon=True
        )
        thread.start()
        
        return {"id": item.id, "status": item.status, "message": "Download retry started (proxy mode)"}
    else:
        # ë¡œì»¬ ë‹¤ìš´ë¡œë“œ - í ìƒí™©ì— ë”°ë¼ ì¦‰ì‹œ ì‹œìž‘ ë˜ëŠ” ëŒ€ê¸°
        from core.shared import download_manager
        
        if download_manager.can_start_download(item.url):
            # ì¦‰ì‹œ ì‹œìž‘ ê°€ëŠ¥
            # URL íƒ€ìž…ì— ë”°ë¼ ì ì ˆí•œ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ì„ íƒ (ìž¬ì‹œë„ ë¡œì»¬)
            if "1fichier.com" in item.url.lower():
                from .download_core import download_1fichier_file_new
                target_function = download_1fichier_file_new
            else:
                from .download_core import download_general_file
                target_function = download_general_file
            
            import threading
            
            setattr(item, "status", StatusEnum.downloading)
            db.commit()
            
            thread = threading.Thread(
                target=target_function,
                args=(download_id, "ko", original_use_proxy),
                daemon=True
            )
            thread.start()
            
            return {"id": item.id, "status": item.status, "message": "Download retry started (local mode)"}
        else:
            # ëŒ€ê¸° ìƒíƒœë¡œ ìœ ì§€ (ìžë™ í ì‹œìŠ¤í…œì´ ì²˜ë¦¬)
            return {"id": item.id, "status": "waiting", "message": "Download added to queue for retry"}

@router.put("/downloads/{download_id}/proxy-toggle")
def toggle_download_proxy_mode(download_id: int, db: Session = Depends(get_db)):
    """ë‹¤ìš´ë¡œë“œ í•­ëª©ì˜ í”„ë¡ì‹œ ëª¨ë“œ í† ê¸€"""
    item = db.query(DownloadRequest).filter(DownloadRequest.id == download_id).first()
    if item is None:
        raise HTTPException(status_code=404, detail="Download not found")
    
    # ì‹¤í–‰ ì¤‘ì¸ ë‹¤ìš´ë¡œë“œëŠ” í† ê¸€ ë¶ˆê°€
    if item.status not in [StatusEnum.stopped, StatusEnum.failed, StatusEnum.done]:
        raise HTTPException(status_code=400, detail="Cannot toggle proxy mode for active downloads")
    
    # í”„ë¡ì‹œ ëª¨ë“œ í† ê¸€
    current_use_proxy = getattr(item, 'use_proxy', False)
    new_use_proxy = not current_use_proxy
    setattr(item, 'use_proxy', new_use_proxy)
    db.commit()
    
    print(f"[LOG] ë‹¤ìš´ë¡œë“œ ID {download_id} í”„ë¡ì‹œ ëª¨ë“œ ë³€ê²½: {current_use_proxy} -> {new_use_proxy}")
    
    return {
        "id": item.id,
        "use_proxy": new_use_proxy,
        "message": f"Proxy mode changed to {'proxy' if new_use_proxy else 'local'}"
    }

